"""
Gemini AI Chatbot Integration
Intelligent chatbot for safety and compliance data analysis using Google's Gemini API
"""
import dotenv
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import json
import re
import requests
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Gemini API configuration
GEMINI_API_KEY = dotenv.get_key('.env', 'GEMINI_API_KEY')  # Load from .env file
GEMINI_API_URL = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent'

# Note: In production, you would use the actual Google Gemini API
# For this demo, we'll create a comprehensive mock implementation

class GeminiChatbot:
    """Intelligent chatbot for safety and compliance data analysis"""
    
    def __init__(self, unified_data, kpi_data):
        self.unified_data = unified_data
        self.kpi_data = kpi_data
        self.conversation_history = []
        
        # Initialize knowledge base
        self.knowledge_base = self._build_knowledge_base()
        
        # Common queries and responses
        self.query_patterns = {
            'total_incidents': ['ÙƒÙ… Ø¹Ø¯Ø¯ Ø§Ù„Ø­ÙˆØ§Ø¯Ø«', 'Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø­ÙˆØ§Ø¯Ø«', 'total incidents'],
            'open_cases': ['Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©', 'Ø§Ù„Ù…ÙØªÙˆØ­', 'open cases'],
            'closed_cases': ['Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø©', 'Ø§Ù„Ù…ØºÙ„Ù‚', 'closed cases'],
            'department_performance': ['Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù‚Ø·Ø§Ø¹', 'Ø§Ù„Ù‚Ø·Ø§Ø¹Ø§Øª', 'department performance'],
            'risk_assessment': ['ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø±', 'Ø§Ù„Ù…Ø®Ø§Ø·Ø±', 'risk assessment'],
            'compliance_rate': ['Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„', 'Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„', 'compliance rate'],
            'trends': ['Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª', 'Ø§Ù„ØªØ·ÙˆØ±', 'trends', 'trend'],
            'statistics': ['Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª', 'statistics', 'stats']
        }
    
    def _analyze_columns(self, df):
        """Analyze dataframe columns and categorize them by type"""
        column_analysis = {
            'date_columns': [],
            'numeric_columns': [],
            'categorical_columns': [],
            'text_columns': [],
            'status_columns': [],
            'department_columns': []
        }
        
        for col in df.columns:
            col_lower = str(col).lower()
            # Analyze column type and content
            if df[col].dtype == 'datetime64[ns]' or any(x in col_lower for x in ['ØªØ§Ø±ÙŠØ®', 'date', 'ÙˆÙ‚Øª', 'time']):
                column_analysis['date_columns'].append(col)
            elif df[col].dtype in ['int64', 'float64'] or any(x in col_lower for x in ['Ø¹Ø¯Ø¯', 'number', 'ÙƒÙ…ÙŠØ©', 'quantity']):
                column_analysis['numeric_columns'].append(col)
            elif any(x in col_lower for x in ['Ø­Ø§Ù„Ø©', 'status', 'Ù…ØºÙ„Ù‚', 'Ù…ÙØªÙˆØ­']):
                column_analysis['status_columns'].append(col)
            elif any(x in col_lower for x in ['Ø¥Ø¯Ø§Ø±Ø©', 'Ù‚Ø·Ø§Ø¹', 'department']):
                column_analysis['department_columns'].append(col)
            elif df[col].dtype == 'object' and df[col].nunique() <= 20:
                column_analysis['categorical_columns'].append(col)
            else:
                column_analysis['text_columns'].append(col)
        
        return column_analysis
    
    def _suggest_visualizations(self, df, columns, query):
        """Suggest appropriate visualizations based on column types and query"""
        charts = []
        query_lower = query.lower()
        
        # Time series analysis
        if any(word in query_lower for word in ['ØªØ·ÙˆØ±', 'Ø§ØªØ¬Ø§Ù‡', 'trend', 'over time']) and columns['date_columns']:
            date_col = columns['date_columns'][0]
            if columns['numeric_columns']:
                for num_col in columns['numeric_columns'][:2]:  # Limit to 2 metrics
                    fig = go.Figure()
                    df[date_col] = pd.to_datetime(df[date_col])
                    monthly_data = df.groupby(df[date_col].dt.strftime('%Y-%m'))[num_col].mean()
                    fig.add_trace(go.Scatter(
                        x=monthly_data.index,
                        y=monthly_data.values,
                        mode='lines+markers',
                        name=num_col
                    ))
                    fig.update_layout(
                        title=f"ØªØ·ÙˆØ± {num_col} Ø¹Ø¨Ø± Ø§Ù„Ø²Ù…Ù†",
                        xaxis_title="Ø§Ù„Ø´Ù‡Ø±",
                        yaxis_title=num_col,
                        template="plotly_white"
                    )
                    charts.append(fig)
        
        # Distribution analysis
        if any(word in query_lower for word in ['ØªÙˆØ²ÙŠØ¹', 'distribution']):
            if columns['categorical_columns']:
                for cat_col in columns['categorical_columns'][:2]:  # Limit to 2 categories
                    value_counts = df[cat_col].value_counts()
                    fig = px.pie(
                        values=value_counts.values,
                        names=value_counts.index,
                        title=f"ØªÙˆØ²ÙŠØ¹ {cat_col}"
                    )
                    charts.append(fig)
        
        # Status analysis
        if any(word in query_lower for word in ['Ø­Ø§Ù„Ø©', 'status']) and columns['status_columns']:
            for status_col in columns['status_columns']:
                value_counts = df[status_col].value_counts()
                fig = go.Figure(data=[
                    go.Pie(
                        labels=value_counts.index,
                        values=value_counts.values,
                        hole=.3
                    )
                ])
                fig.update_layout(
                    title=f"ØªÙˆØ²ÙŠØ¹ {status_col}",
                    template="plotly_white"
                )
                charts.append(fig)
        
        # Department performance
        if any(word in query_lower for word in ['Ù‚Ø·Ø§Ø¹', 'Ø¥Ø¯Ø§Ø±Ø©', 'department']) and columns['department_columns']:
            dept_col = columns['department_columns'][0]
            if columns['numeric_columns']:
                for metric in columns['numeric_columns'][:2]:
                    dept_metrics = df.groupby(dept_col)[metric].mean().sort_values(ascending=False)
                    fig = px.bar(
                        x=dept_metrics.index,
                        y=dept_metrics.values,
                        title=f"{metric} Ø­Ø³Ø¨ {dept_col}",
                        labels={'x': dept_col, 'y': metric}
                    )
                    charts.append(fig)
        
        return charts
    
    def _build_knowledge_base(self):
        """Build knowledge base from unified data"""
        knowledge = {
            'data_summary': {},
            'key_metrics': {},
            'insights': [],
            'column_analysis': {}  # Add column analysis to knowledge base
        }
        
        total_records = 0
        total_open = 0
        total_closed = 0
        dept_counts = {}
        
        # Build data summary
        for data_type, df in self.unified_data.items():
            if isinstance(df, pd.DataFrame) and not df.empty:
                total_records += len(df)
                
                # Status analysis
                status_col = next((col for col in df.columns 
                                 if any(x in str(col).lower() for x in ['Ø­Ø§Ù„Ø©', 'status'])), None)
                if status_col:
                    closed = df[status_col].str.contains('Ù…ØºÙ„Ù‚|closed', case=False, na=False).sum()
                    opened = len(df) - closed
                    total_closed += closed
                    total_open += opened
                
                # Department analysis
                dept_col = next((col for col in df.columns 
                               if any(x in str(col).lower() for x in ['Ø¥Ø¯Ø§Ø±Ø©', 'Ù‚Ø·Ø§Ø¹', 'department'])), None)
                if dept_col:
                    for dept, count in df[dept_col].value_counts().items():
                        dept_counts[dept] = dept_counts.get(dept, 0) + count
                
                knowledge['data_summary'][data_type] = {
                    'total_records': len(df),
                    'columns': list(df.columns),
                    'date_range': self._get_date_range(df),
                    'key_statistics': self._get_key_statistics(df)
                }
        
        # Build key metrics
        knowledge['key_metrics'] = self.kpi_data if self.kpi_data else {}
        
        # Generate main insights
        insights = []
        insights.append(f"ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¹Ù„Ù‰ Ø¥Ø¬Ù…Ø§Ù„ÙŠ {total_records:,} Ø³Ø¬Ù„ Ø¹Ø¨Ø± Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
        
        if total_open + total_closed > 0:
            compliance_rate = (total_closed / (total_open + total_closed)) * 100
            insights.append(f"Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù‡Ùˆ {compliance_rate:.1f}% ({total_closed:,} Ù…ØºÙ„Ù‚ Ù…Ù† Ø£ØµÙ„ {total_open + total_closed:,})")
        
        if dept_counts:
            top_dept = max(dept_counts.items(), key=lambda x: x[1])
            insights.append(f"Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø£ÙƒØ«Ø± Ù†Ø´Ø§Ø·Ø§Ù‹ Ù‡Ùˆ {top_dept[0]} Ø¨Ù€ {top_dept[1]:,} Ø³Ø¬Ù„")
        
        knowledge['insights'] = insights
        
        return knowledge
    
    def _get_date_range(self, df):
        """Get date range from dataframe"""
        date_columns = [col for col in df.columns if df[col].dtype == 'datetime64[ns]']
        if not date_columns:
            return None
        
        all_dates = pd.concat([df[col].dropna() for col in date_columns])
        if len(all_dates) == 0:
            return None
        
        return {
            'start': all_dates.min().strftime('%Y-%m-%d'),
            'end': all_dates.max().strftime('%Y-%m-%d'),
            'days': (all_dates.max() - all_dates.min()).days
        }
    
    def _get_key_statistics(self, df):
        """Get key statistics from dataframe"""
        stats = {}
        
        # Status distribution
        status_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['Ø­Ø§Ù„Ø©', 'status'])]
        if status_cols:
            status_dist = df[status_cols[0]].value_counts().to_dict()
            stats['status_distribution'] = status_dist
        
        # Department distribution
        dept_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['Ø¥Ø¯Ø§Ø±Ø©', 'Ù‚Ø·Ø§Ø¹', 'department'])]
        if dept_cols:
            dept_dist = df[dept_cols[0]].value_counts().head(5).to_dict()
            stats['top_departments'] = dept_dist
        
        return stats
    
    def _generate_insights(self):
        """Generate automatic insights from data"""
        insights = []
        
        # Total records insight
        total_records = sum([len(df) for df in self.unified_data.values() if not df.empty])
        insights.append(f"ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¹Ù„Ù‰ Ø¥Ø¬Ù…Ø§Ù„ÙŠ {total_records:,} Ø³Ø¬Ù„ Ø¹Ø¨Ø± Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
        
        # Compliance insight
        total_open = 0
        total_closed = 0
        
        for data_type, df in self.unified_data.items():
            if df.empty:
                continue
            
            for col in df.columns:
                if any(keyword in col.lower() for keyword in ['Ø­Ø§Ù„Ø©', 'status']):
                    status_counts = df[col].value_counts()
                    for status, count in status_counts.items():
                        if 'Ù…ÙØªÙˆØ­' in str(status):
                            total_open += count
                        elif 'Ù…ØºÙ„Ù‚' in str(status):
                            total_closed += count
        
        if total_open + total_closed > 0:
            compliance_rate = (total_closed / (total_open + total_closed)) * 100
            insights.append(f"Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù‡Ùˆ {compliance_rate:.1f}% ({total_closed:,} Ù…ØºÙ„Ù‚ Ù…Ù† Ø£ØµÙ„ {total_open + total_closed:,})")
        
        # Department insight
        dept_performance = {}
        for data_type, df in self.unified_data.items():
            if df.empty:
                continue
            
            dept_col = None
            status_col = None
            
            for col in df.columns:
                if any(keyword in col.lower() for keyword in ['Ø¥Ø¯Ø§Ø±Ø©', 'Ù‚Ø·Ø§Ø¹', 'department']):
                    dept_col = col
                elif any(keyword in col.lower() for keyword in ['Ø­Ø§Ù„Ø©', 'status']):
                    status_col = col
            
            if dept_col and status_col:
                dept_counts = df[dept_col].value_counts()
                top_dept = dept_counts.index[0] if len(dept_counts) > 0 else None
                if top_dept:
                    insights.append(f"Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø£ÙƒØ«Ø± Ù†Ø´Ø§Ø·Ø§Ù‹ Ù‡Ùˆ {top_dept} Ø¨Ù€ {dept_counts.iloc[0]:,} Ø³Ø¬Ù„")
                    break
        
        return insights
    
    def call_gemini_api(self, prompt):
        """Call Gemini API with the given prompt"""
        try:
            url = f"{GEMINI_API_URL}?key={GEMINI_API_KEY}"
            
            payload = {
                "contents": [{
                    "parts": [{
                        "text": prompt
                    }]
                }]
            }
            
            headers = {
                'Content-Type': 'application/json'
            }
            
            response = requests.post(url, headers=headers, json=payload)
            response.raise_for_status()
            
            result = response.json()
            if 'candidates' in result and len(result['candidates']) > 0:
                return result['candidates'][0]['content']['parts'][0]['text']
            else:
                return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† ÙÙ‡Ù… Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø±. Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„ØŸ"
                
        except Exception as e:
            st.error(f"Error calling Gemini API: {str(e)}")
            return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø±. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰."
    
    def _prepare_context_for_gemini(self):
        """Prepare context about the data for Gemini"""
        context = "Ø£Ù†Ø§ Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³Ù„Ø§Ù…Ø© ÙˆØ§Ù„Ø§Ù…ØªØ«Ø§Ù„. Ù„Ø¯ÙŠ Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© ÙˆØ³Ø£Ù‚ÙˆÙ… Ø¨ØªØ­Ù„ÙŠÙ„Ù‡Ø§:\n\n"
        
        # Process and analyze data first
        incidents_data = None
        for data_type, df in self.unified_data.items():
            if 'Ø­ÙˆØ§Ø¯Ø«' in str(data_type) and not df.empty:
                incidents_data = df
                break
        
        # Add specific incident analysis if available
        if incidents_data is not None:
            # Find date column
            date_col = None
            for col in incidents_data.columns:
                if any(x in str(col).lower() for x in ['ØªØ§Ø±ÙŠØ®', 'date']):
                    date_col = col
                    break
            
            if date_col:
                try:
                    incidents_data[date_col] = pd.to_datetime(incidents_data[date_col], errors='coerce')
                    latest_incidents = incidents_data.sort_values(date_col, ascending=False).head(5)
                    
                    context += "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­ÙˆØ§Ø¯Ø«:\n"
                    context += f"â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ø­ÙˆØ§Ø¯Ø«: {len(incidents_data)}\n"
                    context += f"â€¢ Ø¢Ø®Ø± ØªØ§Ø±ÙŠØ® Ø­Ø§Ø¯Ø«: {latest_incidents[date_col].iloc[0].strftime('%Y-%m-%d')}\n"
                    context += "\nØ¢Ø®Ø± 5 Ø­ÙˆØ§Ø¯Ø«:\n"
                    
                    desc_col = next((col for col in incidents_data.columns if any(x in str(col).lower() for x in ['ÙˆØµÙ', 'description', 'ØªÙØ§ØµÙŠÙ„'])), None)
                    
                    for idx, incident in latest_incidents.iterrows():
                        incident_desc = incident[desc_col] if desc_col else "Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙˆØµÙ"
                        incident_date = incident[date_col].strftime('%Y-%m-%d')
                        context += f"â€¢ {incident_date}: {incident_desc[:100]}...\n"
                except Exception as e:
                    context += f"\nÙ…Ù„Ø§Ø­Ø¸Ø©: ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­ÙˆØ§Ø¯Ø« ÙˆÙ„ÙƒÙ† Ù‡Ù†Ø§Ùƒ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®: {str(e)}\n"
        
        # Add general data overview
        context += "\nØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø©:\n"
        for data_type, df in self.unified_data.items():
            if not df.empty:
                context += f"â€¢ {data_type}: {len(df)} Ø³Ø¬Ù„\n"
                context += f"  - Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: {', '.join(df.columns[:5])}... ÙˆØºÙŠØ±Ù‡Ø§\n"
        
        if self.kpi_data:
            context += "\nÙ…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„Ù…ØªÙˆÙØ±Ø©:\n"
            for kpi_name, kpi_value in self.kpi_data.items():
                context += f"â€¢ {kpi_name}\n"
        
        return context

    def analyze_data_for_query(self, query):
        """Analyze data based on the query and generate visualizations"""
        query_lower = query.lower()
        response_text = ""
        fig = None
        data = None

        # Check different query types and generate appropriate visualizations
        if any(word in query_lower for word in ['Ø­ÙˆØ§Ø¯Ø«', 'Ø­Ø§Ø¯Ø«', 'Ø¢Ø®Ø±']):
            # Find incidents data
            incidents_data = None
            for data_type, df in self.unified_data.items():
                if any(x in str(data_type).lower() for x in ['Ø­ÙˆØ§Ø¯Ø«', 'incidents']) and not df.empty:
                    incidents_data = df.copy()  # Create a copy to avoid modifying original
                    break
            
            if incidents_data is not None:
                # Find date column
                date_col = next((col for col in incidents_data.columns 
                               if any(x in str(col).lower() for x in ['ØªØ§Ø±ÙŠØ®', 'date', 'ÙˆÙ‚Øª', 'time'])), None)
                
                if date_col:
                    try:
                        # Convert dates and handle errors
                        incidents_data[date_col] = pd.to_datetime(incidents_data[date_col], errors='coerce')
                        incidents_data = incidents_data.dropna(subset=[date_col])  # Remove rows with invalid dates
                        
                        # Get latest incidents
                        latest_incidents = incidents_data.sort_values(date_col, ascending=False).head(5)
                        
                        # Create monthly trend chart
                        fig = go.Figure()
                        monthly_counts = incidents_data.groupby(incidents_data[date_col].dt.strftime('%Y-%m'))[date_col].count()
                        
                        fig.add_trace(go.Scatter(
                            x=monthly_counts.index,
                            y=monthly_counts.values,
                            mode='lines+markers',
                            name='Ø¹Ø¯Ø¯ Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ø§Ù„Ø´Ù‡Ø±ÙŠ',
                            line=dict(color='#1f77b4', width=2),
                            marker=dict(size=8)
                        ))
                        
                        fig.update_layout(
                            title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ø§Ù„Ø´Ù‡Ø±ÙŠ",
                            xaxis_title="Ø§Ù„Ø´Ù‡Ø±",
                            yaxis_title="Ø¹Ø¯Ø¯ Ø§Ù„Ø­ÙˆØ§Ø¯Ø«",
                            template="plotly_white",
                            showlegend=True,
                            hovermode='x unified'
                        )
                        
                        data = latest_incidents
                        response_text = "ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­ÙˆØ§Ø¯Ø«:\n\n"
                        response_text += f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ø­ÙˆØ§Ø¯Ø«: {len(incidents_data)}\n"
                        response_text += f"ğŸ“… Ø¢Ø®Ø± ØªØ§Ø±ÙŠØ® Ø­Ø§Ø¯Ø«: {latest_incidents[date_col].iloc[0].strftime('%Y-%m-%d')}\n\n"
                        response_text += "Ø¢Ø®Ø± 5 Ø­ÙˆØ§Ø¯Ø«:\n"
                        
                        desc_col = next((col for col in incidents_data.columns 
                                       if any(x in str(col).lower() for x in ['ÙˆØµÙ', 'description'])), None)
                        
                        for idx, incident in latest_incidents.iterrows():
                            incident_desc = incident[desc_col] if desc_col else "Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙˆØµÙ"
                            incident_date = incident[date_col].strftime('%Y-%m-%d')
                            response_text += f"\nğŸ“Œ {incident_date}: {incident_desc}"
                    except Exception as e:
                        response_text = f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­ÙˆØ§Ø¯Ø«: {str(e)}"

        elif any(word in query_lower for word in ['Ù…Ø®Ø§Ø·Ø±', 'Ø®Ø·Ø±', 'risk']):
            risk_data = None
            for data_type, df in self.unified_data.items():
                if 'Ù…Ø®Ø§Ø·Ø±' in str(data_type) and not df.empty:
                    risk_data = df
                    break
            
            if risk_data is not None:
                risk_level_col = next((col for col in risk_data.columns 
                                     if any(x in str(col).lower() for x in ['Ù…Ø³ØªÙˆÙ‰', 'level'])), None)
                
                if risk_level_col:
                    risk_counts = risk_data[risk_level_col].value_counts()
                    
                    fig = px.pie(
                        values=risk_counts.values,
                        names=risk_counts.index,
                        title="ØªÙˆØ²ÙŠØ¹ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù…Ø®Ø§Ø·Ø±"
                    )
                    
                    data = risk_data
                    response_text = "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø®Ø§Ø·Ø±:\n\n"
                    response_text += f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø®Ø§Ø·Ø±: {len(risk_data)}\n\n"
                    response_text += "ØªÙˆØ²ÙŠØ¹ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù…Ø®Ø§Ø·Ø±:\n"
                    for level, count in risk_counts.items():
                        response_text += f"â€¢ {level}: {count} ({count/len(risk_data)*100:.1f}%)\n"

        elif any(word in query_lower for word in ['Ø§Ù…ØªØ«Ø§Ù„', 'compliance']):
            total_open = 0
            total_closed = 0
            compliance_data = {}
            
            for data_type, df in self.unified_data.items():
                if df.empty:
                    continue
                
                status_col = next((col for col in df.columns 
                                 if any(x in str(col).lower() for x in ['Ø­Ø§Ù„Ø©', 'status'])), None)
                
                if status_col:
                    closed = df[status_col].str.contains('Ù…ØºÙ„Ù‚|closed', case=False, na=False).sum()
                    opened = len(df) - closed
                    total_closed += closed
                    total_open += opened
                    compliance_data[data_type] = {'Ù…ØºÙ„Ù‚': closed, 'Ù…ÙØªÙˆØ­': opened}
            
            if compliance_data:
                fig = go.Figure()
                for status in ['Ù…ØºÙ„Ù‚', 'Ù…ÙØªÙˆØ­']:
                    values = [data[status] for data in compliance_data.values()]
                    fig.add_trace(go.Bar(
                        name=status,
                        x=list(compliance_data.keys()),
                        y=values
                    ))
                
                fig.update_layout(
                    barmode='stack',
                    title="Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
                    xaxis_title="Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
                    yaxis_title="Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª"
                )
                
                total = total_open + total_closed
                compliance_rate = (total_closed / total * 100) if total > 0 else 0
                
                response_text = "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„:\n\n"
                response_text += f"ğŸ“Š Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {compliance_rate:.1f}%\n"
                response_text += f"âœ… Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø©: {total_closed}\n"
                response_text += f"â³ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©: {total_open}\n"

        return response_text, fig, data

    def process_query(self, user_query):
        """Process user query and generate data-driven response with visualizations"""
        user_query = user_query.strip()
        query_lower = user_query.lower()
        
        # Add to conversation history
        self.conversation_history.append({
            'timestamp': datetime.now(),
            'user_query': user_query,
            'response': None
        })
        
        try:
            # First try to analyze the query specifically
            response = self._analyze_data_for_query(user_query)
            
            # If no specific analysis found, try general overview
            if not response and any(word in query_lower for word in ['ØªØµÙˆØ±', 'Ø¹Ø§Ù…', 'Ù†Ø¸Ø±Ø©', 'overview', 'general']):
                # Initialize data for visualization
                data_summary = {
                    'total_records': 0,
                    'closed_count': 0,
                    'open_count': 0,
                    'data_types': {},
                    'departments': {}
                }
                
                # Process each dataset
                for data_type, df in self.unified_data.items():
                    if isinstance(df, pd.DataFrame) and not df.empty:
                        # Count records
                        data_summary['data_types'][data_type] = len(df)
                        data_summary['total_records'] += len(df)
                        
                        # Process status
                        status_col = next((col for col in df.columns 
                                         if any(x in str(col).lower() for x in ['Ø­Ø§Ù„Ø©', 'status'])), None)
                        if status_col:
                            closed = df[status_col].str.contains('Ù…ØºÙ„Ù‚|closed', case=False, na=False).sum()
                            data_summary['closed_count'] += closed
                            data_summary['open_count'] += len(df) - closed
                        
                        # Process departments
                        dept_col = next((col for col in df.columns 
                                       if any(x in str(col).lower() for x in ['Ù‚Ø·Ø§Ø¹', 'Ø¥Ø¯Ø§Ø±Ø©', 'department'])), None)
                        if dept_col:
                            dept_counts = df[dept_col].value_counts()
                            for dept, count in dept_counts.items():
                                if dept in data_summary['departments']:
                                    data_summary['departments'][dept] += count
                                else:
                                    data_summary['departments'][dept] = count
                
                # Create separate figures for better control
                
                # First figure: Data types distribution
                fig1 = go.Figure()
                data_types_values = list(data_summary['data_types'].values())
                data_types_labels = list(data_summary['data_types'].keys())
                
                fig1.add_trace(go.Bar(
                    x=data_types_labels,
                    y=data_types_values,
                    marker_color='#1f77b4',
                    text=data_types_values,
                    textposition='auto',
                ))
                
                fig1.update_layout(
                    title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹",
                    height=400,
                    showlegend=False,
                    margin=dict(l=50, r=50, t=80, b=50),
                    paper_bgcolor='white',
                    plot_bgcolor='rgba(0,0,0,0)',
                    xaxis_title="Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
                    yaxis_title="Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª",
                    font=dict(size=14)
                )
                
                # Second figure: Status distribution
                fig2 = None
                if data_summary['closed_count'] + data_summary['open_count'] > 0:
                    fig2 = go.Figure()
                    fig2.add_trace(go.Pie(
                        values=[data_summary['closed_count'], data_summary['open_count']],
                        labels=['Ù…ØºÙ„Ù‚', 'Ù…ÙØªÙˆØ­'],
                        hole=.4,
                        marker_colors=['#2ecc71', '#e74c3c'],
                        textinfo='label+percent',
                        textposition='inside'
                    ))
                    
                    fig2.update_layout(
                        title="ØªÙˆØ²ÙŠØ¹ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ù„ÙØ§Øª",
                        height=400,
                        showlegend=True,
                        margin=dict(l=50, r=50, t=80, b=50),
                        paper_bgcolor='white',
                        font=dict(size=14)
                    )
                
                # Calculate compliance rate
                total_files = data_summary['closed_count'] + data_summary['open_count']
                compliance_rate = (data_summary['closed_count'] / total_files * 100) if total_files > 0 else 0
                
                # Find top department
                top_dept = max(data_summary['departments'].items(), key=lambda x: x[1]) if data_summary['departments'] else None
                
                # Generate response text
                response_text = "Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n\n"
                response_text += f"â€¢ ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¹Ù„Ù‰ Ø¥Ø¬Ù…Ø§Ù„ÙŠ {data_summary['total_records']:,} Ø³Ø¬Ù„ Ø¹Ø¨Ø± Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n"
                if total_files > 0:
                    response_text += f"â€¢ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù‡Ùˆ {compliance_rate:.1f}% ({data_summary['closed_count']:,} Ù…ØºÙ„Ù‚ Ù…Ù† Ø£ØµÙ„ {total_files:,})\n"
                if top_dept:
                    response_text += f"â€¢ Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø£ÙƒØ«Ø± Ù†Ø´Ø§Ø·Ø§Ù‹ Ù‡Ùˆ {top_dept[0]} Ø¨Ù€ {top_dept[1]:,} Ø³Ø¬Ù„\n"
                
                # Create response with both charts
                charts = []
                if fig1 is not None:
                    charts.append(fig1)
                if fig2 is not None:
                    charts.append(fig2)
                
                # Create response dictionary with proper chart handling
                response = {
                    'text': response_text,
                    'data': pd.DataFrame(list(data_summary['data_types'].items()), 
                                       columns=['Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª', 'Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª'])
                }
                
                # Add charts only if we have them
                if len(charts) > 0:
                    response['charts'] = charts
                    # For backward compatibility
                    response['chart'] = charts[0] if len(charts) > 0 else None
            else:
                # For other queries
                query_type = self._classify_query(user_query)
                response = self._generate_response(query_type, user_query)
                
                if not response or not response.get('text'):
                    response = self._analyze_data_for_query(user_query)
                
                if not response or not response.get('text'):
                    # If no specific analysis, use Gemini API with context
                    context = self._prepare_context_for_gemini()
                    gemini_prompt = f"""Based on the following data context:

{context}

Please analyze and answer this question (in Arabic):
{user_query}

Focus on:
1. Direct answer using available data
2. Key statistics and metrics
3. Insights and recommendations

Response MUST be in Arabic and maintain a professional, analytical tone."""
                    
                    gemini_response = self.call_gemini_api(gemini_prompt)
                    response = {
                        'text': gemini_response,
                        'chart': self._generate_relevant_chart(user_query),
                        'data': None
                    }            # Add response to conversation history
            self.conversation_history[-1]['response'] = response
            return response
            
        except Exception as e:
            error_response = {
                'text': f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ø³ØªÙØ³Ø§Ø±Ùƒ: {str(e)}",
                'chart': None,
                'data': None
            }
            self.conversation_history[-1]['response'] = error_response
            return error_response
    
    def _analyze_data_for_query(self, query):
        """Analyze data based on query content"""
        query_lower = query.lower()
        response_text = ""
        charts = []
        data = None
        
        # Define query categories and their keywords
        query_categories = {
            'incidents': ['Ø­ÙˆØ§Ø¯Ø«', 'Ø­Ø§Ø¯Ø«', 'accident', 'incident'],
            'risks': ['Ù…Ø®Ø§Ø·Ø±', 'Ø®Ø·Ø±', 'risk', 'hazard'],
            'inspections': ['ØªÙØªÙŠØ´', 'ÙØ­Øµ', 'inspection'],
            'compliance': ['Ø§Ù…ØªØ«Ø§Ù„', 'Ø§Ù„ØªØ²Ø§Ù…', 'compliance'],
            'performance': ['Ø£Ø¯Ø§Ø¡', 'performance', 'Ù‚Ø·Ø§Ø¹', 'Ø¥Ø¯Ø§Ø±Ø©'],
            'trends': ['ØªØ·ÙˆØ±', 'Ø§ØªØ¬Ø§Ù‡', 'trend', 'ØªØºÙŠØ±'],
            'distribution': ['ØªÙˆØ²ÙŠØ¹', 'distribution', 'ØªÙ‚Ø³ÙŠÙ…']
        }
        
        # Find relevant datasets based on query
        relevant_data = {}
        for data_type, df in self.unified_data.items():
            if not df.empty:
                # Analyze columns for this dataset
                columns = self._analyze_columns(df)
                if columns:  # If we have analyzable columns
                    relevant_data[data_type] = {
                        'df': df,
                        'columns': columns
                    }
        
        # For general data overview
        if any(word in query_lower for word in ['Ø¹Ø§Ù…', 'ØªØµÙˆØ±', 'Ù†Ø¸Ø±Ø©', 'overview', 'general']):
            all_stats = {
                'total_records': 0,
                'open_cases': 0,
                'closed_cases': 0,
                'types_distribution': {},
                'dept_stats': {}
            }
            
            for data_type, df in self.unified_data.items():
                if isinstance(df, pd.DataFrame) and not df.empty:
                    # Basic counts
                    all_stats['types_distribution'][data_type] = len(df)
                    all_stats['total_records'] += len(df)
                    
                    # Status analysis
                    status_col = next((col for col in df.columns 
                                     if any(x in str(col).lower() for x in ['Ø­Ø§Ù„Ø©', 'status'])), None)
                    if status_col:
                        closed = df[status_col].str.contains('Ù…ØºÙ„Ù‚|closed', case=False, na=False).sum()
                        all_stats['closed_cases'] += closed
                        all_stats['open_cases'] += (len(df) - closed)
                    
                    # Department analysis
                    dept_col = next((col for col in df.columns 
                                   if any(x in str(col).lower() for x in ['Ø¥Ø¯Ø§Ø±Ø©', 'Ù‚Ø·Ø§Ø¹', 'department'])), None)
                    if dept_col:
                        dept_counts = df[dept_col].value_counts()
                        for dept, count in dept_counts.items():
                            if dept not in all_stats['dept_stats']:
                                all_stats['dept_stats'][dept] = 0
                            all_stats['dept_stats'][dept] += count
            
            if all_stats['total_records'] > 0:
                # Create main visualization
                fig = go.Figure()
                
                # Types distribution
                fig.add_trace(go.Bar(
                    name='ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª',
                    x=list(all_stats['types_distribution'].keys()),
                    y=list(all_stats['types_distribution'].values()),
                    text=list(all_stats['types_distribution'].values()),
                    textposition='auto',
                ))
                
                # Status overview if available
                if all_stats['open_cases'] + all_stats['closed_cases'] > 0:
                    fig.add_trace(go.Pie(
                        values=[all_stats['open_cases'], all_stats['closed_cases']],
                        labels=['Ù…ÙØªÙˆØ­', 'Ù…ØºÙ„Ù‚'],
                        domain={'x': [0.7, 1], 'y': [0, 1]},
                        name='Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ù„ÙØ§Øª',
                        hole=.4,
                        textinfo='percent+label'
                    ))
                
                fig.update_layout(
                    title="Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
                    showlegend=True,
                    height=500,
                    grid={'rows': 1, 'columns': 2},
                    annotations=[
                        dict(text="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", x=0.25, y=1.1, showarrow=False, font_size=16),
                        dict(text="Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ù„ÙØ§Øª", x=0.85, y=1.1, showarrow=False, font_size=16)
                    ]
                )
                
                # Generate response text
                response_text = f"""Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:

ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª: {all_stats['total_records']:,}

Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ù„ÙØ§Øª:
âœ… Ù…ØºÙ„Ù‚: {all_stats['closed_cases']:,}
â³ Ù…ÙØªÙˆØ­: {all_stats['open_cases']:,}

ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:"""
                
                for data_type, count in all_stats['types_distribution'].items():
                    response_text += f"\nâ€¢ {data_type}: {count:,} Ø³Ø¬Ù„"
                
                if all_stats['dept_stats']:
                    response_text += "\n\nØ£Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø·Ø§Ø¹Ø§Øª Ù†Ø´Ø§Ø·Ø§Ù‹:"
                    top_depts = sorted(all_stats['dept_stats'].items(), key=lambda x: x[1], reverse=True)[:3]
                    for dept, count in top_depts:
                        response_text += f"\nâ€¢ {dept}: {count:,} Ø³Ø¬Ù„"
                
                data = pd.DataFrame({
                    'Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª': list(all_stats['types_distribution'].keys()),
                    'Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª': list(all_stats['types_distribution'].values()),
                    'Ø§Ù„Ù†Ø³Ø¨Ø©': [f"{(v/all_stats['total_records'])*100:.1f}%" 
                              for v in all_stats['types_distribution'].values()]
                })
                
                return {
                    'text': response_text,
                    'chart': fig,
                    'data': data
                }
        
        # Check different aspects of the query
        elif any(word in query_lower for word in ['Ø­ÙˆØ§Ø¯Ø«', 'Ø­Ø§Ø¯Ø«', 'Ø¢Ø®Ø±', 'incident']):
            for data_type, df in self.unified_data.items():
                if 'Ø­ÙˆØ§Ø¯Ø«' in str(data_type) and not df.empty:
                    date_col = next((col for col in df.columns 
                                   if any(x in str(col).lower() for x in ['ØªØ§Ø±ÙŠØ®', 'date'])), None)
                    
                    if date_col:
                        try:
                            df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
                            latest = df.sort_values(date_col, ascending=False).head(5)
                            
                            monthly_counts = df.groupby(df[date_col].dt.strftime('%Y-%m'))[date_col].count()
                            
                            fig = go.Figure()
                            fig.add_trace(go.Scatter(
                                x=monthly_counts.index,
                                y=monthly_counts.values,
                                mode='lines+markers',
                                name='Ø¹Ø¯Ø¯ Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ø§Ù„Ø´Ù‡Ø±ÙŠ'
                            ))
                            
                            fig.update_layout(
                                title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ø§Ù„Ø´Ù‡Ø±ÙŠ",
                                xaxis_title="Ø§Ù„Ø´Ù‡Ø±",
                                yaxis_title="Ø¹Ø¯Ø¯ Ø§Ù„Ø­ÙˆØ§Ø¯Ø«"
                            )
                            
                            response_text = f"ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­ÙˆØ§Ø¯Ø«:\n\n"
                            response_text += f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ø­ÙˆØ§Ø¯Ø«: {len(df)}\n"
                            response_text += f"ğŸ“… Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«: {latest[date_col].iloc[0].strftime('%Y-%m-%d')}\n\n"
                            
                            desc_col = next((col for col in df.columns 
                                           if any(x in str(col).lower() for x in ['ÙˆØµÙ', 'description'])), None)
                            
                            if desc_col:
                                response_text += "Ø¢Ø®Ø± 5 Ø­ÙˆØ§Ø¯Ø«:\n"
                                for _, row in latest.iterrows():
                                    response_text += f"\nğŸ“Œ {row[date_col].strftime('%Y-%m-%d')}: {row[desc_col]}"
                            
                            data = latest
                            break
                        except Exception as e:
                            continue
        
        elif any(word in query_lower for word in ['Ù…Ø®Ø§Ø·Ø±', 'Ø®Ø·Ø±', 'risk']):
            for data_type, df in self.unified_data.items():
                if 'Ù…Ø®Ø§Ø·Ø±' in str(data_type) and not df.empty:
                    risk_col = next((col for col in df.columns 
                                   if any(x in str(col).lower() for x in ['Ù…Ø³ØªÙˆÙ‰', 'ØªØµÙ†ÙŠÙ', 'level'])), None)
                    
                    if risk_col:
                        risk_counts = df[risk_col].value_counts()
                        
                        fig = px.pie(
                            values=risk_counts.values,
                            names=risk_counts.index,
                            title="ØªÙˆØ²ÙŠØ¹ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù…Ø®Ø§Ø·Ø±"
                        )
                        
                        response_text = "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø®Ø§Ø·Ø±:\n\n"
                        response_text += f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø®Ø§Ø·Ø±: {len(df)}\n\n"
                        response_text += "ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø­Ø³Ø¨ Ø§Ù„Ù…Ø³ØªÙˆÙ‰:\n"
                        for level, count in risk_counts.items():
                            response_text += f"â€¢ {level}: {count} ({count/len(df)*100:.1f}%)\n"
                        
                        data = df
                        break
        
        elif any(word in query_lower for word in ['Ø§Ù…ØªØ«Ø§Ù„', 'compliance']):
            total_open = 0
            total_closed = 0
            compliance_data = {}
            
            for data_type, df in self.unified_data.items():
                if df.empty:
                    continue
                
                status_col = next((col for col in df.columns 
                                 if any(x in str(col).lower() for x in ['Ø­Ø§Ù„Ø©', 'status'])), None)
                
                if status_col:
                    closed = df[status_col].str.contains('Ù…ØºÙ„Ù‚|closed', case=False, na=False).sum()
                    opened = len(df) - closed
                    total_closed += closed
                    total_open += opened
                    compliance_data[data_type] = {'Ù…ØºÙ„Ù‚': closed, 'Ù…ÙØªÙˆØ­': opened}
            
            if compliance_data:
                fig = go.Figure()
                for status in ['Ù…ØºÙ„Ù‚', 'Ù…ÙØªÙˆØ­']:
                    values = [data[status] for data in compliance_data.values()]
                    fig.add_trace(go.Bar(
                        name=status,
                        x=list(compliance_data.keys()),
                        y=values
                    ))
                
                fig.update_layout(
                    barmode='stack',
                    title="Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
                    xaxis_title="Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
                    yaxis_title="Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª"
                )
                
                total = total_open + total_closed
                compliance_rate = (total_closed / total * 100) if total > 0 else 0
                
                response_text = "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„:\n\n"
                response_text += f"ğŸ“Š Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {compliance_rate:.1f}%\n"
                response_text += f"âœ… Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø©: {total_closed}\n"
                response_text += f"â³ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©: {total_open}\n\n"
                response_text += "Ø§Ù„ØªÙØµÙŠÙ„ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n"
                
                for data_type, counts in compliance_data.items():
                    total = counts['Ù…ØºÙ„Ù‚'] + counts['Ù…ÙØªÙˆØ­']
                    rate = (counts['Ù…ØºÙ„Ù‚'] / total * 100) if total > 0 else 0
                    response_text += f"\nâ€¢ {data_type}:"
                    response_text += f"\n  - Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„: {rate:.1f}%"
                    response_text += f"\n  - Ù…ØºÙ„Ù‚: {counts['Ù…ØºÙ„Ù‚']}"
                    response_text += f"\n  - Ù…ÙØªÙˆØ­: {counts['Ù…ÙØªÙˆØ­']}"
        
        return {
            'text': response_text,
            'chart': fig,
            'data': data
        } if response_text else None
    
    def _generate_relevant_chart(self, query):
        """Generate a relevant chart based on the query context"""
        query_lower = query.lower()
        
        try:
            # For time-based queries
            if any(word in query_lower for word in ['Ù…ØªÙ‰', 'ØªØ§Ø±ÙŠØ®', 'Ø´Ù‡Ø±', 'Ø³Ù†Ø©', 'when', 'date', 'month', 'year']):
                relevant_data = None
                date_col = None
                
                # Find most relevant dataset with dates
                for data_type, df in self.unified_data.items():
                    if df.empty:
                        continue
                        
                    for col in df.columns:
                        if any(x in str(col).lower() for x in ['ØªØ§Ø±ÙŠØ®', 'date']):
                            relevant_data = df
                            date_col = col
                            break
                    if relevant_data is not None:
                        break
                
                if relevant_data is not None and date_col:
                    try:
                        relevant_data[date_col] = pd.to_datetime(relevant_data[date_col], errors='coerce')
                        monthly_counts = relevant_data.groupby(relevant_data[date_col].dt.strftime('%Y-%m')).size()
                        
                        fig = go.Figure()
                        fig.add_trace(go.Scatter(
                            x=monthly_counts.index,
                            y=monthly_counts.values,
                            mode='lines+markers',
                            name='Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø´Ù‡Ø±ÙŠ'
                        ))
                        
                        fig.update_layout(
                            title="Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø²Ù…Ù†ÙŠ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
                            xaxis_title="Ø§Ù„Ø´Ù‡Ø±",
                            yaxis_title="Ø§Ù„Ø¹Ø¯Ø¯"
                        )
                        
                        return fig
                    except:
                        pass
            
            # For comparison queries
            elif any(word in query_lower for word in ['Ù…Ù‚Ø§Ø±Ù†Ø©', 'compare', 'versus', 'vs']):
                data_counts = {data_type: len(df) for data_type, df in self.unified_data.items() if not df.empty}
                
                if data_counts:
                    fig = go.Figure()
                    fig.add_trace(go.Bar(
                        x=list(data_counts.keys()),
                        y=list(data_counts.values())
                    ))
                    
                    fig.update_layout(
                        title="Ù…Ù‚Ø§Ø±Ù†Ø© Ø­Ø¬Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
                        xaxis_title="Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
                        yaxis_title="Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª"
                    )
                    
                    return fig
            
            # For distribution queries
            elif any(word in query_lower for word in ['ØªÙˆØ²ÙŠØ¹', 'distribution']):
                for data_type, df in self.unified_data.items():
                    if df.empty:
                        continue
                    
                    categorical_cols = df.select_dtypes(include=['object']).columns
                    for col in categorical_cols:
                        if len(df[col].unique()) <= 10:  # Only for columns with reasonable number of categories
                            value_counts = df[col].value_counts()
                            
                            fig = px.pie(
                                values=value_counts.values,
                                names=value_counts.index,
                                title=f"ØªÙˆØ²ÙŠØ¹ {col}"
                            )
                            
                            return fig
                            break
                    break
        
        except Exception:
            pass
        
        return None
    
    def _classify_query(self, query):
        """Classify user query into categories"""
        query_lower = query.lower()
        
        # Initial classification from query patterns
        for category, patterns in self.query_patterns.items():
            for pattern in patterns:
                if pattern.lower() in query_lower:
                    return category
        
        # Enhanced classification based on topic analysis
        if any(word in query_lower for word in ['Ø­ÙˆØ§Ø¯Ø«', 'Ø­Ø§Ø¯Ø«', 'incident', 'accidents']):
            return 'total_incidents'
        elif any(word in query_lower for word in ['Ù…ÙØªÙˆØ­', 'Ø¬Ø§Ø±ÙŠ', 'Ù‚ÙŠØ¯ Ø§Ù„ØªÙ†ÙÙŠØ°', 'open', 'pending']):
            return 'open_cases'
        elif any(word in query_lower for word in ['Ù…ØºÙ„Ù‚', 'Ù…Ù†ØªÙ‡ÙŠ', 'ØªÙ…', 'closed', 'done']):
            return 'closed_cases'
        elif any(word in query_lower for word in ['Ù‚Ø·Ø§Ø¹', 'Ø¥Ø¯Ø§Ø±Ø©', 'Ø£Ø¯Ø§Ø¡', 'department', 'performance']):
            return 'department_performance'
        elif any(word in query_lower for word in ['Ù…Ø®Ø§Ø·Ø±', 'Ø®Ø·Ø±', 'risk', 'hazard']):
            return 'risk_assessment'
        elif any(word in query_lower for word in ['Ø§Ù…ØªØ«Ø§Ù„', 'Ø§Ù„ØªØ²Ø§Ù…', 'compliance']):
            return 'compliance_rate'
        elif any(word in query_lower for word in ['Ø§ØªØ¬Ø§Ù‡', 'ØªØ·ÙˆØ±', 'trend', 'progress']):
            return 'trends'
        elif any(word in query_lower for word in ['Ø¥Ø­ØµØ§Ø¡', 'Ø¹Ø¯Ø¯', 'ÙƒÙ…', 'statistics', 'count']):
            return 'statistics'
        
        # Fallback classification
        return 'general'
    
    def _generate_response(self, query_type, user_query):
        """Generate response based on query type"""
        try:
            if query_type == 'total_incidents':
                return self._get_incidents_summary()
            elif query_type == 'open_cases':
                return self._get_open_cases_summary()
            elif query_type == 'closed_cases':
                return self._get_closed_cases_summary()
            elif query_type == 'department_performance':
                return self._get_department_performance()
            elif query_type == 'risk_assessment':
                return self._get_risk_assessment_summary()
            elif query_type == 'compliance_rate':
                return self._get_compliance_summary()
            elif query_type == 'trends':
                return self._get_trends_summary()
            elif query_type == 'statistics':
                return self._get_general_statistics()
            else:
                return self._get_general_response(user_query)
        except Exception as e:
            return {
                'text': f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ø³ØªÙØ³Ø§Ø±Ùƒ: {str(e)}",
                'chart': None,
                'data': None
            }
    
    def _get_incidents_summary(self):
        """Get incidents summary"""
        # Find incidents data in any of the datasets
        incidents_data = None
        for data_type, df in self.unified_data.items():
            if any(x in str(data_type).lower() for x in ['Ø­ÙˆØ§Ø¯Ø«', 'incidents']) and not df.empty:
                incidents_data = df
                break
                
        if incidents_data is None:
            return {
                'text': "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø­ÙˆØ§Ø¯Ø« Ù…ØªØ§Ø­Ø© ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø­Ø§Ù„ÙŠØ§Ù‹.",
                'charts': None,
                'data': None
            }
        
        incidents_df = self.unified_data['incidents']
        total_incidents = len(incidents_df)
        
        # Get status distribution
        status_dist = {}
        for col in incidents_df.columns:
            if any(keyword in col.lower() for keyword in ['Ø­Ø§Ù„Ø©', 'status']):
                status_dist = incidents_df[col].value_counts().to_dict()
                break
        
        # Create chart
        if status_dist:
            chart_data = pd.DataFrame([
                {'Ø§Ù„Ø­Ø§Ù„Ø©': status, 'Ø§Ù„Ø¹Ø¯Ø¯': count}
                for status, count in status_dist.items()
            ])
            
            fig = px.pie(
                chart_data,
                values='Ø§Ù„Ø¹Ø¯Ø¯',
                names='Ø§Ù„Ø­Ø§Ù„Ø©',
                title="ØªÙˆØ²ÙŠØ¹ Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø­ÙˆØ§Ø¯Ø«"
            )
        else:
            fig = None
        
        text = f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ø§Ù„Ù…Ø³Ø¬Ù„Ø©: {total_incidents:,} Ø­Ø§Ø¯Ø«\n"
        if status_dist:
            text += "ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø­Ø§Ù„Ø§Øª:\n"
            for status, count in status_dist.items():
                text += f"â€¢ {status}: {count:,} Ø­Ø§Ø¯Ø«\n"
        
        return {
            'text': text,
            'chart': fig,
            'data': incidents_df.head(10)
        }
    
    def _get_open_cases_summary(self):
        """Get open cases summary"""
        open_cases = {}
        total_open = 0
        
        for data_type, df in self.unified_data.items():
            if df.empty:
                continue
            
            for col in df.columns:
                if any(keyword in col.lower() for keyword in ['Ø­Ø§Ù„Ø©', 'status']):
                    open_count = len(df[df[col].str.contains('Ù…ÙØªÙˆØ­', na=False)])
                    if open_count > 0:
                        open_cases[data_type] = open_count
                        total_open += open_count
                    break
        
        if not open_cases:
            return {
                'text': "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø­Ø§Ù„Ø§Øª Ù…ÙØªÙˆØ­Ø© ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø­Ø§Ù„ÙŠØ§Ù‹.",
                'chart': None,
                'data': None
            }
        
        # Create chart
        chart_data = pd.DataFrame([
            {'Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª': data_type, 'Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©': count}
            for data_type, count in open_cases.items()
        ])
        
        fig = px.bar(
            chart_data,
            x='Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª',
            y='Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©',
            title="Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"
        )
        
        text = f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©: {total_open:,}\n"
        text += "Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n"
        for data_type, count in open_cases.items():
            text += f"â€¢ {data_type}: {count:,} Ø­Ø§Ù„Ø© Ù…ÙØªÙˆØ­Ø©\n"
        
        return {
            'text': text,
            'chart': fig,
            'data': chart_data
        }
    
    def _get_closed_cases_summary(self):
        """Get closed cases summary"""
        closed_cases = {}
        total_closed = 0
        
        for data_type, df in self.unified_data.items():
            if df.empty:
                continue
            
            for col in df.columns:
                if any(keyword in col.lower() for keyword in ['Ø­Ø§Ù„Ø©', 'status']):
                    closed_count = len(df[df[col].str.contains('Ù…ØºÙ„Ù‚', na=False)])
                    if closed_count > 0:
                        closed_cases[data_type] = closed_count
                        total_closed += closed_count
                    break
        
        if not closed_cases:
            return {
                'text': "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø­Ø§Ù„Ø§Øª Ù…ØºÙ„Ù‚Ø© ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø­Ø§Ù„ÙŠØ§Ù‹.",
                'chart': None,
                'data': None
            }
        
        # Create chart
        chart_data = pd.DataFrame([
            {'Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª': data_type, 'Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø©': count}
            for data_type, count in closed_cases.items()
        ])
        
        fig = px.bar(
            chart_data,
            x='Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª',
            y='Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø©',
            title="Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
            color_discrete_sequence=['#2ca02c']
        )
        
        text = f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø©: {total_closed:,}\n"
        text += "Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n"
        for data_type, count in closed_cases.items():
            text += f"â€¢ {data_type}: {count:,} Ø­Ø§Ù„Ø© Ù…ØºÙ„Ù‚Ø©\n"
        
        return {
            'text': text,
            'chart': fig,
            'data': chart_data
        }
    
    def _get_department_performance(self):
        """Get department performance analysis"""
        dept_performance = {}
        
        for data_type, df in self.unified_data.items():
            if df.empty:
                continue
            
            dept_col = None
            status_col = None
            
            for col in df.columns:
                if any(keyword in col.lower() for keyword in ['Ø¥Ø¯Ø§Ø±Ø©', 'Ù‚Ø·Ø§Ø¹', 'department']):
                    dept_col = col
                elif any(keyword in col.lower() for keyword in ['Ø­Ø§Ù„Ø©', 'status']):
                    status_col = col
            
            if dept_col and status_col:
                dept_status = df.groupby(dept_col)[status_col].value_counts().unstack(fill_value=0)
                for dept in dept_status.index:
                    closed = dept_status.loc[dept].get('Ù…ØºÙ„Ù‚', 0)
                    total = dept_status.loc[dept].sum()
                    compliance_rate = (closed / total * 100) if total > 0 else 0
                    
                    if dept not in dept_performance:
                        dept_performance[dept] = {'total': 0, 'closed': 0, 'rates': []}
                    
                    dept_performance[dept]['total'] += total
                    dept_performance[dept]['closed'] += closed
                    dept_performance[dept]['rates'].append(compliance_rate)
        
        if not dept_performance:
            return {
                'text': "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù‚Ø·Ø§Ø¹Ø§Øª Ù…ØªØ§Ø­Ø©.",
                'chart': None,
                'data': None
            }
        
        # Calculate average performance
        performance_data = []
        for dept, data in dept_performance.items():
            avg_rate = np.mean(data['rates']) if data['rates'] else 0
            performance_data.append({
                'Ø§Ù„Ù‚Ø·Ø§Ø¹': dept,
                'Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„': avg_rate,
                'Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø­Ø§Ù„Ø§Øª': data['total'],
                'Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø©': data['closed']
            })
        
        performance_df = pd.DataFrame(performance_data)
        performance_df = performance_df.sort_values('Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„', ascending=False)
        
        # Create chart
        fig = px.bar(
            performance_df.head(10),
            x='Ø§Ù„Ù‚Ø·Ø§Ø¹',
            y='Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„',
            title="Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù‚Ø·Ø§Ø¹Ø§Øª - Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„",
            color='Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„',
            color_continuous_scale='RdYlGn'
        )
        fig.update_layout(xaxis_tickangle=-45)
        
        # Generate text summary
        best_dept = performance_df.iloc[0]
        worst_dept = performance_df.iloc[-1]
        
        text = f"ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù‚Ø·Ø§Ø¹Ø§Øª:\n\n"
        text += f"Ø£ÙØ¶Ù„ Ù‚Ø·Ø§Ø¹: {best_dept['Ø§Ù„Ù‚Ø·Ø§Ø¹']} Ø¨Ù…Ø¹Ø¯Ù„ Ø§Ù…ØªØ«Ø§Ù„ {best_dept['Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„']:.1f}%\n"
        text += f"Ø£Ø¶Ø¹Ù Ù‚Ø·Ø§Ø¹: {worst_dept['Ø§Ù„Ù‚Ø·Ø§Ø¹']} Ø¨Ù…Ø¹Ø¯Ù„ Ø§Ù…ØªØ«Ø§Ù„ {worst_dept['Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„']:.1f}%\n\n"
        text += f"Ù…ØªÙˆØ³Ø· Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ø§Ù„Ø¹Ø§Ù…: {performance_df['Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„'].mean():.1f}%"
        
        return {
            'text': text,
            'chart': fig,
            'data': performance_df
        }
    
    def _get_risk_assessment_summary(self):
        """Get risk assessment summary"""
        if 'risk_assessments' not in self.unified_data or self.unified_data['risk_assessments'].empty:
            return {
                'text': "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ù…ØªØ§Ø­Ø© ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø­Ø§Ù„ÙŠØ§Ù‹.",
                'chart': None,
                'data': None
            }
        
        risk_df = self.unified_data['risk_assessments']
        total_assessments = len(risk_df)
        
        # Get risk level distribution
        risk_levels = {'Ø¹Ø§Ù„ÙŠ': 0, 'Ù…ØªÙˆØ³Ø·': 0, 'Ù…Ù†Ø®ÙØ¶': 0}
        
        for col in risk_df.columns:
            if any(keyword in col.lower() for keyword in ['ØªØµÙ†ÙŠÙ', 'Ù…Ø®Ø§Ø·Ø±', 'risk']):
                level_counts = risk_df[col].value_counts()
                for level, count in level_counts.items():
                    level_str = str(level).lower()
                    if 'Ø¹Ø§Ù„ÙŠ' in level_str or 'high' in level_str:
                        risk_levels['Ø¹Ø§Ù„ÙŠ'] += count
                    elif 'Ù…ØªÙˆØ³Ø·' in level_str or 'medium' in level_str:
                        risk_levels['Ù…ØªÙˆØ³Ø·'] += count
                    elif 'Ù…Ù†Ø®ÙØ¶' in level_str or 'low' in level_str:
                        risk_levels['Ù…Ù†Ø®ÙØ¶'] += count
                break
        
        # Create chart
        chart_data = pd.DataFrame([
            {'Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø±': level, 'Ø§Ù„Ø¹Ø¯Ø¯': count}
            for level, count in risk_levels.items() if count > 0
        ])
        
        if not chart_data.empty:
            fig = px.pie(
                chart_data,
                values='Ø§Ù„Ø¹Ø¯Ø¯',
                names='Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø±',
                title="ØªÙˆØ²ÙŠØ¹ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù…Ø®Ø§Ø·Ø±",
                color_discrete_map={
                    'Ø¹Ø§Ù„ÙŠ': '#d62728',
                    'Ù…ØªÙˆØ³Ø·': '#ff7f0e',
                    'Ù…Ù†Ø®ÙØ¶': '#2ca02c'
                }
            )
        else:
            fig = None
        
        text = f"Ù…Ù„Ø®Øµ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø±:\n\n"
        text += f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…Ø§Øª: {total_assessments:,}\n"
        if any(risk_levels.values()):
            text += "ØªÙˆØ²ÙŠØ¹ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù…Ø®Ø§Ø·Ø±:\n"
            for level, count in risk_levels.items():
                if count > 0:
                    percentage = (count / sum(risk_levels.values())) * 100
                    text += f"â€¢ {level}: {count:,} ({percentage:.1f}%)\n"
        
        return {
            'text': text,
            'chart': fig,
            'data': risk_df.head(10)
        }
    
    def _get_compliance_summary(self):
        """Get overall compliance summary"""
        total_open = 0
        total_closed = 0
        compliance_by_type = {}
        
        for data_type, df in self.unified_data.items():
            if df.empty:
                continue
            
            type_open = 0
            type_closed = 0
            
            for col in df.columns:
                if any(keyword in col.lower() for keyword in ['Ø­Ø§Ù„Ø©', 'status']):
                    status_counts = df[col].value_counts()
                    for status, count in status_counts.items():
                        if 'Ù…ÙØªÙˆØ­' in str(status):
                            type_open += count
                            total_open += count
                        elif 'Ù…ØºÙ„Ù‚' in str(status):
                            type_closed += count
                            total_closed += count
                    break
            
            if type_open + type_closed > 0:
                compliance_rate = (type_closed / (type_open + type_closed)) * 100
                compliance_by_type[data_type] = {
                    'rate': compliance_rate,
                    'closed': type_closed,
                    'total': type_open + type_closed
                }
        
        if total_open + total_closed == 0:
            return {
                'text': "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ø­Ø³Ø§Ø¨ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„.",
                'chart': None,
                'data': None
            }
        
        overall_compliance = (total_closed / (total_open + total_closed)) * 100
        
        # Create chart
        chart_data = pd.DataFrame([
            {'Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª': data_type, 'Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„': data['rate']}
            for data_type, data in compliance_by_type.items()
        ])
        
        fig = px.bar(
            chart_data,
            x='Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª',
            y='Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„',
            title="Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
            color='Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„',
            color_continuous_scale='RdYlGn'
        )
        fig.update_layout(xaxis_tickangle=-45)
        
        text = f"Ù…Ù„Ø®Øµ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ø§Ù„Ø¹Ø§Ù…:\n\n"
        text += f"Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {overall_compliance:.1f}%\n"
        text += f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø­Ø§Ù„Ø§Øª: {total_open + total_closed:,}\n"
        text += f"Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø©: {total_closed:,}\n"
        text += f"Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©: {total_open:,}\n\n"
        text += "Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n"
        
        for data_type, data in compliance_by_type.items():
            text += f"â€¢ {data_type}: {data['rate']:.1f}% ({data['closed']}/{data['total']})\n"
        
        return {
            'text': text,
            'chart': fig,
            'data': chart_data
        }
    
    def _get_trends_summary(self):
        """Get trends analysis"""
        trends_data = {}
        
        for data_type, df in self.unified_data.items():
            if df.empty:
                continue
            
            date_col = None
            for col in df.columns:
                if df[col].dtype == 'datetime64[ns]':
                    date_col = col
                    break
            
            if date_col:
                monthly_trend = df.groupby(pd.Grouper(key=date_col, freq='M')).size()
                if len(monthly_trend) > 1:
                    trends_data[data_type] = monthly_trend
        
        if not trends_data:
            return {
                'text': "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©.",
                'chart': None,
                'data': None
            }
        
        # Create combined trends chart
        fig = go.Figure()
        
        for data_type, trend in trends_data.items():
            fig.add_trace(go.Scatter(
                x=trend.index,
                y=trend.values,
                mode='lines+markers',
                name=data_type,
                line=dict(width=2)
            ))
        
        fig.update_layout(
            title="Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
            xaxis_title="Ø§Ù„ØªØ§Ø±ÙŠØ®",
            yaxis_title="Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª",
            hovermode='x unified'
        )
        
        text = "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©:\n\n"
        
        for data_type, trend in trends_data.items():
            latest_value = trend.iloc[-1]
            previous_value = trend.iloc[-2] if len(trend) > 1 else latest_value
            change = ((latest_value - previous_value) / previous_value * 100) if previous_value != 0 else 0
            
            text += f"â€¢ {data_type}:\n"
            text += f"  - Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©: {latest_value:,}\n"
            text += f"  - Ø§Ù„ØªØºÙŠÙŠØ±: {change:+.1f}% Ù…Ù† Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ø³Ø§Ø¨Ù‚\n\n"
        
        return {
            'text': text,
            'chart': fig,
            'data': None
        }
    
    def _get_general_statistics(self):
        """Get general statistics"""
        stats = {
            'total_records': 0,
            'data_types': len(self.unified_data),
            'date_ranges': {},
            'top_departments': {},
            'status_summary': {'Ù…ÙØªÙˆØ­': 0, 'Ù…ØºÙ„Ù‚': 0}
        }
        
        for data_type, df in self.unified_data.items():
            if df.empty:
                continue
            
            stats['total_records'] += len(df)
            
            # Get date range
            date_range = self._get_date_range(df)
            if date_range:
                stats['date_ranges'][data_type] = date_range
            
            # Get department info
            for col in df.columns:
                if any(keyword in col.lower() for keyword in ['Ø¥Ø¯Ø§Ø±Ø©', 'Ù‚Ø·Ø§Ø¹', 'department']):
                    dept_counts = df[col].value_counts().head(3)
                    stats['top_departments'][data_type] = dept_counts.to_dict()
                    break
            
            # Get status info
            for col in df.columns:
                if any(keyword in col.lower() for keyword in ['Ø­Ø§Ù„Ø©', 'status']):
                    status_counts = df[col].value_counts()
                    for status, count in status_counts.items():
                        if 'Ù…ÙØªÙˆØ­' in str(status):
                            stats['status_summary']['Ù…ÙØªÙˆØ­'] += count
                        elif 'Ù…ØºÙ„Ù‚' in str(status):
                            stats['status_summary']['Ù…ØºÙ„Ù‚'] += count
                    break
        
        text = f"Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ù†Ø¸Ø§Ù…:\n\n"
        text += f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª: {stats['total_records']:,}\n"
        text += f"Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {stats['data_types']}\n"
        text += f"Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©: {stats['status_summary']['Ù…ÙØªÙˆØ­']:,}\n"
        text += f"Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø©: {stats['status_summary']['Ù…ØºÙ„Ù‚']:,}\n\n"
        
        if stats['date_ranges']:
            text += "Ø§Ù„Ù†Ø·Ø§Ù‚Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©:\n"
            for data_type, date_range in stats['date_ranges'].items():
                text += f"â€¢ {data_type}: Ù…Ù† {date_range['start']} Ø¥Ù„Ù‰ {date_range['end']} ({date_range['days']} ÙŠÙˆÙ…)\n"
        
        return {
            'text': text,
            'chart': None,
            'data': None
        }
    
    def _get_general_response(self, user_query):
        """Get general response for unclassified queries"""
        query_lower = user_query.lower()
        
        # If it's a general overview query
        if any(word in query_lower for word in ['ØªØµÙˆØ±', 'Ø¹Ø§Ù…', 'Ù†Ø¸Ø±Ø©', 'overview']):
            # Initialize data summaries
            data_summary = {
                'total_records': 0,
                'open_cases': 0,
                'closed_cases': 0,
                'data_types': {},
                'departments': {}
            }
            
            # Process each dataset
            for data_type, df in self.unified_data.items():
                if isinstance(df, pd.DataFrame) and not df.empty:
                    # Count records
                    data_summary['data_types'][data_type] = len(df)
                    data_summary['total_records'] += len(df)
                    
                    # Process status
                    status_col = next((col for col in df.columns 
                                     if any(x in str(col).lower() for x in ['Ø­Ø§Ù„Ø©', 'status'])), None)
                    if status_col:
                        closed = df[status_col].str.contains('Ù…ØºÙ„Ù‚|closed', case=False, na=False).sum()
                        data_summary['closed_cases'] += closed
                        data_summary['open_cases'] += len(df) - closed
                    
                    # Process departments
                    dept_col = next((col for col in df.columns 
                                   if any(x in str(col).lower() for x in ['Ø¥Ø¯Ø§Ø±Ø©', 'Ù‚Ø·Ø§Ø¹', 'department'])), None)
                    if dept_col:
                        for dept, count in df[dept_col].value_counts().items():
                            data_summary['departments'][dept] = data_summary['departments'].get(dept, 0) + count
            
            # Create visualizations
            charts = []
            
            # Data types distribution
            if data_summary['data_types']:
                fig1 = go.Figure(data=[
                    go.Bar(
                        x=list(data_summary['data_types'].keys()),
                        y=list(data_summary['data_types'].values()),
                        text=list(data_summary['data_types'].values()),
                        textposition='auto',
                    )
                ])
                fig1.update_layout(
                    title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹",
                    xaxis_title="Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
                    yaxis_title="Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª",
                    template="plotly_white"
                )
                charts.append(fig1)
            
            # Cases status
            if data_summary['open_cases'] + data_summary['closed_cases'] > 0:
                fig2 = go.Figure(data=[
                    go.Pie(
                        labels=['Ù…ÙØªÙˆØ­', 'Ù…ØºÙ„Ù‚'],
                        values=[data_summary['open_cases'], data_summary['closed_cases']],
                        hole=.3
                    )
                ])
                fig2.update_layout(
                    title="ØªÙˆØ²ÙŠØ¹ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ù„ÙØ§Øª",
                    template="plotly_white"
                )
                charts.append(fig2)
            
            # Generate response text
            total_cases = data_summary['open_cases'] + data_summary['closed_cases']
            compliance_rate = (data_summary['closed_cases'] / total_cases * 100) if total_cases > 0 else 0
            
            # Find top department
            top_dept = max(data_summary['departments'].items(), key=lambda x: x[1]) if data_summary['departments'] else None
            
            text = "Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n\n"
            text += f"â€¢ ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¹Ù„Ù‰ Ø¥Ø¬Ù…Ø§Ù„ÙŠ {data_summary['total_records']:,} Ø³Ø¬Ù„ Ø¹Ø¨Ø± Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n"
            
            if total_cases > 0:
                text += f"â€¢ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù‡Ùˆ {compliance_rate:.1f}% ({data_summary['closed_cases']:,} Ù…ØºÙ„Ù‚ Ù…Ù† Ø£ØµÙ„ {total_cases:,})\n"
            
            if top_dept:
                text += f"â€¢ Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø£ÙƒØ«Ø± Ù†Ø´Ø§Ø·Ø§Ù‹ Ù‡Ùˆ {top_dept[0]} Ø¨Ù€ {top_dept[1]:,} Ø³Ø¬Ù„\n"
            
                # Create detailed data for display
                display_data = pd.DataFrame({
                    'Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª': list(data_summary['data_types'].keys()),
                    'Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª': list(data_summary['data_types'].values()),
                    'Ø§Ù„Ù†Ø³Ø¨Ø©': [f"{(v/data_summary['total_records'])*100:.1f}%" 
                          for v in data_summary['data_types'].values()]
                })
                
                # Generate additional analysis based on available columns
                extra_charts = []
                for data_type, df in self.unified_data.items():
                    if isinstance(df, pd.DataFrame) and not df.empty:
                        # Analyze columns
                        columns = self._analyze_columns(df)
                        
                        # Add relevant visualizations
                        if columns['numeric_columns'] and len(columns['numeric_columns']) >= 2:
                            # Create correlation heatmap for numeric columns
                            numeric_data = df[columns['numeric_columns']].corr()
                            fig = go.Figure(data=go.Heatmap(
                                z=numeric_data.values,
                                x=numeric_data.columns,
                                y=numeric_data.columns,
                                colorscale='RdBu'
                            ))
                            fig.update_layout(
                                title=f"Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· - {data_type}",
                                template="plotly_white"
                            )
                            extra_charts.append(fig)
                        
                        if columns['date_columns'] and columns['numeric_columns']:
                            # Create time series analysis
                            date_col = columns['date_columns'][0]
                            metric_col = columns['numeric_columns'][0]
                            df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
                            monthly_data = df.groupby(df[date_col].dt.strftime('%Y-%m'))[metric_col].mean()
                            
                            fig = go.Figure()
                            fig.add_trace(go.Scatter(
                                x=monthly_data.index,
                                y=monthly_data.values,
                                mode='lines+markers',
                                name=metric_col
                            ))
                            fig.update_layout(
                                title=f"ØªØ·ÙˆØ± {metric_col} Ø¹Ø¨Ø± Ø§Ù„Ø²Ù…Ù† - {data_type}",
                                xaxis_title="Ø§Ù„Ø´Ù‡Ø±",
                                yaxis_title=metric_col,
                                template="plotly_white"
                            )
                            extra_charts.append(fig)
                
                if extra_charts:
                    charts.extend(extra_charts)
            
            return {
                'text': text,
                'charts': charts if charts else None,
                'data': display_data
            }        # For help queries
        elif any(word in query_lower for word in ['Ù…Ø³Ø§Ø¹Ø¯Ø©', 'help']):
            return {
                'text': """ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø± Ø¹Ù†:

â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø­ÙˆØ§Ø¯Ø« ÙˆØ§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª
â€¢ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø© ÙˆØ§Ù„Ù…ØºÙ„Ù‚Ø©
â€¢ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
â€¢ ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ø§Ù„Ù…Ø®Ø§Ø·Ø±
â€¢ Ù…Ø¹Ø¯Ù„Ø§Øª Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„
â€¢ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©
â€¢ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù…Ø©

Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©:
- "ÙƒÙ… Ø¹Ø¯Ø¯ Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ø§Ù„Ù…ÙØªÙˆØ­Ø©ØŸ"
- "Ù…Ø§ Ù‡Ùˆ Ø£Ø¯Ø§Ø¡ Ù‚Ø·Ø§Ø¹ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ØŸ"
- "Ø£Ø¸Ù‡Ø± Ù„ÙŠ Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª"
- "Ù…Ø§ Ù‡Ùˆ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ØŸ"
""",
                'charts': None,
                'data': None
            }
        
        # Default response
        else:
            # Provide insights from knowledge base
            insights_text = "Ø¥Ù„ÙŠÙƒ Ø¨Ø¹Ø¶ Ø§Ù„Ø±Ø¤Ù‰ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n\n"
            for insight in self.knowledge_base['insights'][:3]:
                insights_text += f"â€¢ {insight}\n"
            
            insights_text += "\nÙŠÙ…ÙƒÙ†Ùƒ Ø·Ø±Ø­ Ø£Ø³Ø¦Ù„Ø© Ø£ÙƒØ«Ø± ØªØ­Ø¯ÙŠØ¯Ø§Ù‹ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ù…ÙØµÙ„."
            
            return {
                'text': insights_text,
                'charts': None,
                'data': None
            }
    
    def get_conversation_history(self):
        """Get conversation history"""
        return self.conversation_history
    
    def clear_conversation(self):
        """Clear conversation history"""
        self.conversation_history = []
    
    def export_conversation(self):
        """Export conversation history"""
        if not self.conversation_history:
            return None
        
        conversation_data = []
        for entry in self.conversation_history:
            conversation_data.append({
                'timestamp': entry['timestamp'].strftime('%Y-%m-%d %H:%M:%S'),
                'user_query': entry['user_query'],
                'response_text': entry['response']['text'] if entry['response'] else None
            })
        
        return pd.DataFrame(conversation_data)

def create_chatbot_interface(unified_data, kpi_data):
    """Create interactive chatbot interface in Streamlit"""
    # Apply custom CSS for better visual presentation
    st.markdown("""
    <style>
    .chat-container { 
        padding: 1rem; 
        border-radius: 0.5rem; 
        margin-bottom: 1rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .user-message { 
        background-color: #e3f2fd;
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
    }
    .bot-message { 
        background-color: #f5f5f5;
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
    }
    .chat-meta { 
        font-size: 0.8rem; 
        color: #666;
        margin-top: 0.25rem;
    }
    div[data-testid="stPlotlyChart"] {
        margin: 1rem 0;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        background-color: white;
        padding: 1rem;
    }
    </style>
    """, unsafe_allow_html=True)
    
    st.subheader("ğŸ¤– Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
    
    # Initialize chatbot
    if 'chatbot' not in st.session_state:
        st.session_state.chatbot = GeminiChatbot(unified_data, kpi_data)
    
    # Initialize chat interface
    if 'messages' not in st.session_state:
        st.session_state.messages = []
        
        # Add enhanced welcome message
        welcome_message = {
            "role": "assistant",
            "content": """Ù…Ø±Ø­Ø¨Ø§Ù‹! Ø£Ù†Ø§ Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø°ÙƒÙŠ Ù„ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³Ù„Ø§Ù…Ø© ÙˆØ§Ù„Ø§Ù…ØªØ«Ø§Ù„. ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ:

â€¢ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­ÙˆØ§Ø¯Ø« ÙˆØ¢Ø®Ø± Ø§Ù„Ù…Ø³ØªØ¬Ø¯Ø§Øª
â€¢ Ù…Ø±Ø§Ù‚Ø¨Ø© Ù…Ø¹Ø¯Ù„Ø§Øª Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ ÙˆØ§Ù„Ø¥ØºÙ„Ø§Ù‚
â€¢ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø± ÙˆØªÙˆØ²ÙŠØ¹Ù‡Ø§
â€¢ Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø§Ø±ÙŠØ± Ø¥Ø­ØµØ§Ø¦ÙŠØ©
â€¢ Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© ÙˆØ§Ù„ØªÙˆØ²ÙŠØ¹Ø§Øª

Ù…Ø§ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ ØªØ­Ù„ÙŠÙ„Ù‡ Ø§Ù„ÙŠÙˆÙ…ØŸ""",
            "chart": None,
            "data": None
        }
        st.session_state.messages.append(welcome_message)
    
    # Display chat messages with enhanced visualization handling
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            # Display message content
            st.markdown(message["content"])
            
            # Handle chart display with error checking
            if message.get("charts") is not None:
                try:
                    charts = message["charts"]
                    if isinstance(charts, list) and len(charts) > 0:
                        for chart in charts:
                            if isinstance(chart, go.Figure):
                                # Update layout for better visibility
                                chart.update_layout(
                                    template="plotly_white",
                                    paper_bgcolor="rgba(0,0,0,0)",
                                    plot_bgcolor="rgba(0,0,0,0)",
                                    margin=dict(l=20, r=20, t=40, b=20),
                                )
                                # Display chart
                                st.plotly_chart(chart, use_container_width=True, config={'displayModeBar': True})
                except Exception as e:
                    st.error(f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ: {str(e)}")
            # For backward compatibility
            elif message.get("chart") is not None:
                try:
                    chart = message["chart"]
                    if isinstance(chart, go.Figure):
                        chart.update_layout(
                            template="plotly_white",
                            paper_bgcolor="rgba(0,0,0,0)",
                            plot_bgcolor="rgba(0,0,0,0)",
                            margin=dict(l=20, r=20, t=40, b=20),
                        )
                        st.plotly_chart(chart, use_container_width=True, config={'displayModeBar': True})
                except Exception as e:
                    st.error(f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ: {str(e)}")
            
            # Handle data display with error checking
            if message.get("data") is not None:
                try:
                    with st.expander("ğŸ“Š Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©"):
                        st.dataframe(
                            message["data"],
                            use_container_width=True,
                            height=300,
                            hide_index=True
                        )
                except Exception as e:
                    st.error(f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
    
    # Chat input
    if prompt := st.chat_input("Ø§Ø³Ø£Ù„Ù†ÙŠ Ø¹Ù† ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª..."):
        # Add user message to chat history
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # Display user message
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Get bot response
        with st.chat_message("assistant"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª..."):
                response = st.session_state.chatbot.process_query(prompt)
            
            st.markdown(response['text'])
            
            # Handle charts display
            if 'charts' in response and response['charts']:
                for chart in response['charts']:
                    if isinstance(chart, go.Figure):
                        st.plotly_chart(chart, use_container_width=True)
            elif 'chart' in response and response['chart']:
                if isinstance(response['chart'], go.Figure):
                    st.plotly_chart(response['chart'], use_container_width=True)
            
            # Handle data display
            if response.get('data') is not None:
                with st.expander("Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©"):
                    st.dataframe(response['data'])
            
            # Add assistant response to chat history
            message = {
                "role": "assistant",
                "content": response['text'],
                "data": response.get('data')
            }
            
            # Handle charts in message
            if 'charts' in response and response['charts']:
                message['charts'] = response['charts']
            elif 'chart' in response and response['chart']:
                message['chart'] = response['chart']
            
            # Add message to chat history
            st.session_state.messages.append(message)    
            
            # Sidebar controls
    with st.sidebar:
        st.markdown("### âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©")
        
        if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"):
            st.session_state.messages = []
            st.session_state.chatbot.conversation_history = []
            st.rerun()
        
        st.markdown("### ğŸ’¡ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„")
        suggestions = [
            "Ø¢Ø®Ø± Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ø§Ù„Ù…Ø³Ø¬Ù„Ø©",
            "ØªØ­Ù„ÙŠÙ„ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„",
            "ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø®Ø§Ø·Ø±",
            "Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù…Ø©"
        ]
        
        for suggestion in suggestions:
            if st.button(suggestion, key=f"suggest_{suggestion}"):
                # Simulate clicking the suggestion
                st.session_state.messages.append({"role": "user", "content": suggestion})
                
                with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„..."):
                    response = st.session_state.chatbot.process_query(suggestion)
                
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": response['text'],
                    "chart": response['chart'],
                    "data": response['data']
                })
                st.rerun()