"""
Business Logic Module for the Safety & Compliance Dashboard.
Handles calculations, aggregations, and advanced analytics based on unified data.
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import sys
import os
import json # Import json for serialization

# Ensure the config directory is in the path for imports
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'config'))

try:
    from config.settings import SECTORS, RISK_ACTIVITIES, STATUS_OPTIONS, PRIORITY_OPTIONS, RISK_LEVELS
except ImportError:
    # Fallback for local testing if config.settings is not directly accessible
    SECTORS = ["Ù‚Ø·Ø§Ø¹ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹", "Ù‚Ø·Ø§Ø¹ Ø§Ù„ØªØ´ØºÙŠÙ„", "Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø®Ø¯Ù…Ø§Øª", "Ù‚Ø·Ø§Ø¹ Ø§Ù„ØªØ®ØµÙŠØµ", "Ø£Ø®Ø±Ù‰"]
    RISK_ACTIVITIES = ["Ø§Ù„Ø£Ù…Ø§ÙƒÙ† Ø§Ù„Ù…ØºÙ„Ù‚Ø©", "Ø§Ù„Ø§Ø±ØªÙØ§Ø¹Ø§Øª", "Ø§Ù„Ø­ÙØ±ÙŠØ§Øª", "Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¡"]
    STATUS_OPTIONS = ["Ø§Ù„ÙƒÙ„", "Ù…ÙØªÙˆØ­", "Ù…ØºÙ„Ù‚", "Ù‚ÙŠØ¯ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©", "Ù…ÙƒØªÙ…Ù„"]
    PRIORITY_OPTIONS = ["Ø§Ù„ÙƒÙ„", "Ø¹Ø§Ù„ÙŠ", "Ù…ØªÙˆØ³Ø·", "Ù…Ù†Ø®ÙØ¶"]
    RISK_LEVELS = ["Ø§Ù„ÙƒÙ„", "Ù…Ø±ØªÙØ¹", "Ù…ØªÙˆØ³Ø·", "Ù…Ù†Ø®ÙØ¶"]


class DashboardAnalyzer:
    """
    Analyzes unified safety and compliance data to generate insights,
    KPIs, and detailed reports.
    """

    def __init__(self):
        pass # No complex initialization needed here, data is passed to methods

    def _apply_common_filters(self, df: pd.DataFrame, filters: dict, 
                              date_col_name: str = 'Ø§Ù„ØªØ§Ø±ÙŠØ®', 
                              sector_col_name: str = 'Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©',
                              status_col_name: str = 'Ø§Ù„Ø­Ø§Ù„Ø©',
                              activity_col_name: str = 'Ø§Ù„Ù†Ø´Ø§Ø·',
                              risk_level_col_name: str = 'Ø§Ù„ØªØµÙ†ÙŠÙ',
                              search_col_names: list = None):
        """
        Applies common filters (date range, sectors, status, priority, risk level, text search) to a DataFrame.
        Assumes standardized column names for filtering.
        """
        filtered_df = df.copy()

        # Apply date range filter
        if 'date_range' in filters and len(filters['date_range']) == 2:
            start_date, end_date = filters['date_range']
            if date_col_name in filtered_df.columns and pd.api.types.is_datetime64_any_dtype(filtered_df[date_col_name]):
                date_mask = (filtered_df[date_col_name] >= pd.Timestamp(start_date)) & \
                            (filtered_df[date_col_name] <= pd.Timestamp(end_date))
                filtered_df = filtered_df[date_mask]

        # Apply sector filter
        if 'sectors' in filters and filters['sectors']:
            actual_sector_col = None
            if sector_col_name in filtered_df.columns:
                actual_sector_col = sector_col_name
            elif 'Ø§Ù„Ù‚Ø·Ø§Ø¹' in filtered_df.columns:
                actual_sector_col = 'Ø§Ù„Ù‚Ø·Ø§Ø¹'

            if actual_sector_col:
                sector_mask = filtered_df[actual_sector_col].isin(filters['sectors'])
                filtered_df = filtered_df[sector_mask]
        
        # Apply status filter
        if 'status' in filters and filters['status'] and 'Ø§Ù„ÙƒÙ„' not in filters['status']:
            if status_col_name in filtered_df.columns:
                status_mask = filtered_df[status_col_name].astype(str).str.contains('|'.join(filters['status']), case=False, na=False)
                filtered_df = filtered_df[status_mask]

        # Apply priority filter (assuming 'Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©' column exists and contains string values like 'Ø¹Ø§Ù„ÙŠ', 'Ù…ØªÙˆØ³Ø·', 'Ù…Ù†Ø®ÙØ¶', 'Ø¹Ø§Ø¬Ù„')
        if 'priority' in filters and filters['priority'] != "Ø§Ù„ÙƒÙ„":
            if 'Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©' in filtered_df.columns:
                priority_mask = filtered_df['Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©'].astype(str).str.contains(filters['priority'], case=False, na=False)
                filtered_df = filtered_df[priority_mask]

        # Apply risk level filter (assuming 'Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø±' column exists and contains string values)
        if 'risk_level' in filters and filters['risk_level'] != "Ø§Ù„ÙƒÙ„":
            if 'Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø±' in filtered_df.columns:
                risk_level_mask = filtered_df['Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø±'].astype(str).str.contains(filters['risk_level'], case=False, na=False)
                filtered_df = filtered_df[risk_level_mask]

        # Apply text search filter
        if 'search_query' in filters and filters['search_query']:
            query = filters['search_query']
            if search_col_names is None:
                # Default to all object (string) columns if not specified
                search_col_names = filtered_df.select_dtypes(include=['object']).columns.tolist()
            
            if search_col_names:
                search_mask = filtered_df[search_col_names[0]].astype(str).str.contains(query, case=False, na=False)
                for col in search_col_names[1:]:
                    if col in filtered_df.columns:
                        search_mask |= filtered_df[col].astype(str).str.contains(query, case=False, na=False)
                filtered_df = filtered_df[search_mask]

        return filtered_df

    def get_compliance_summary(self, unified_data: dict, filters: dict = None) -> pd.DataFrame:
        """
        Generates a compliance summary DataFrame by sector.
        Calculates compliance percentage, trend, and priority.
        """
        inspections_df = unified_data.get('inspections', pd.DataFrame())
        
        if inspections_df.empty:
            return pd.DataFrame()

        # Apply common filters
        filtered_inspections_df = self._apply_common_filters(
            inspections_df, filters,
            date_col_name='Ø§Ù„ØªØ§Ø±ÙŠØ®',
            sector_col_name='Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©',
            status_col_name='Ø§Ù„Ø­Ø§Ù„Ø©'
        )

        compliance_data = []

        if 'Ø§Ù„Ø­Ø§Ù„Ø©' not in filtered_inspections_df.columns or 'Ø§Ù„ØªØ§Ø±ÙŠØ®' not in filtered_inspections_df.columns:
            return pd.DataFrame()
        if not pd.api.types.is_datetime64_any_dtype(filtered_inspections_df['Ø§Ù„ØªØ§Ø±ÙŠØ®']):
            return pd.DataFrame()
        
        actual_sector_col = 'Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©' if 'Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©' in filtered_inspections_df.columns else \
                            'Ø§Ù„Ù‚Ø·Ø§Ø¹' if 'Ø§Ù„Ù‚Ø·Ø§Ø¹' in filtered_inspections_df.columns else None
        if actual_sector_col is None:
            return pd.DataFrame()

        available_sectors_in_data = filtered_inspections_df[actual_sector_col].dropna().unique().tolist()
        sectors_to_analyze = filters.get('sectors', available_sectors_in_data)
        if not sectors_to_analyze:
             sectors_to_analyze = SECTORS # Fallback to predefined if no sectors found

        for sector in sorted(list(set(sectors_to_analyze))):
            sector_df = filtered_inspections_df[
                filtered_inspections_df[actual_sector_col].astype(str).str.contains(str(sector), case=False, na=False)
            ]
            
            if sector_df.empty:
                continue
            
            total_records = len(sector_df)
            closed_records = sector_df['Ø§Ù„Ø­Ø§Ù„Ø©'].astype(str).str.contains('Ù…ØºÙ„Ù‚|Ù…ÙƒØªÙ…Ù„', case=False, na=False).sum()
            
            compliance_percentage = (closed_records / total_records * 100) if total_records > 0 else 0

            # Trend analysis (last 90 days vs. overall)
            recent_records_df = sector_df[sector_df['Ø§Ù„ØªØ§Ø±ÙŠØ®'] >= (pd.Timestamp.now() - pd.Timedelta(days=90))]
            recent_compliance = 0
            if not recent_records_df.empty:
                recent_closed = recent_records_df['Ø§Ù„Ø­Ø§Ù„Ø©'].astype(str).str.contains('Ù…ØºÙ„Ù‚|Ù…ÙƒØªÙ…Ù„', case=False, na=False).sum()
                recent_compliance = (recent_closed / len(recent_records_df) * 100) if len(recent_records_df) > 0 else 0
            
            trend = recent_compliance - compliance_percentage

            # Enhanced recommendations based on multiple factors
            recommendation = "Ù„Ø§ ØªÙˆØ¬Ø¯ ØªÙˆØµÙŠØ© Ù…Ø­Ø¯Ø¯Ø©"
            status_color = "âšª"
            priority = "Ù…ØªÙˆØ³Ø·"

            if compliance_percentage >= 90:
                if trend >= 0:
                    recommendation = "Ù…Ù…ØªØ§Ø² - Ø§Ø³ØªÙ…Ø± ÙÙŠ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¬ÙŠØ¯"
                    status_color = "ğŸŸ¢"
                    priority = "Ù…Ù†Ø®ÙØ¶"
                else:
                    recommendation = "Ù…Ù…ØªØ§Ø² Ù…Ø¹ ØªÙ†Ø¨ÙŠÙ‡ - Ø±Ø§Ù‚Ø¨ Ø§Ù„Ø§Ù†Ø®ÙØ§Ø¶ Ø§Ù„Ø£Ø®ÙŠØ±"
                    status_color = "ğŸŸ¢"
                    priority = "Ù…ØªÙˆØ³Ø·"
            elif compliance_percentage >= 70:
                if trend > 5:
                    recommendation = "Ø¬ÙŠØ¯ Ù…Ø¹ ØªØ­Ø³Ù† - Ø§Ø³ØªÙ…Ø± ÙÙŠ Ø§Ù„ØªØ·ÙˆÙŠØ±"
                    status_color = "ğŸŸ¡"
                    priority = "Ù…ØªÙˆØ³Ø·"
                elif trend < -5:
                    recommendation = "ÙŠØ­ØªØ§Ø¬ Ø§Ù‡ØªÙ…Ø§Ù… - Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ ÙÙŠ Ø§Ù†Ø®ÙØ§Ø¶"
                    status_color = "ğŸŸ¡"
                    priority = "Ø¹Ø§Ù„ÙŠ"
                else:
                    recommendation = "Ø¬ÙŠØ¯ - ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ† Ø·ÙÙŠÙ"
                    status_color = "ğŸŸ¡"
                    priority = "Ù…ØªÙˆØ³Ø·"
            else: # Below 70%
                if trend > 5:
                    recommendation = "ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ† Ù…Ø¹ ÙˆØ¬ÙˆØ¯ ØªÙ‚Ø¯Ù… Ø¥ÙŠØ¬Ø§Ø¨ÙŠ"
                    status_color = "ğŸ”´"
                    priority = "Ø¹Ø§Ù„ÙŠ"
                else:
                    recommendation = "ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ† Ø¹Ø§Ø¬Ù„ ÙˆØ®Ø·Ø© Ø¹Ù…Ù„ ÙÙˆØ±ÙŠØ©"
                    status_color = "ğŸ”´"
                    priority = "Ø¹Ø§Ø¬Ù„"

            sector_data = {
                'Ø§Ù„Ù‚Ø·Ø§Ø¹': sector,
                'Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª': total_records,
                'Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø©': int(closed_records),
                'Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©': int(total_records - closed_records),
                'Ù†Ø³Ø¨Ø© Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ %': float(compliance_percentage),
                'Ø§ØªØ¬Ø§Ù‡ Ø§Ù„ØªØºÙŠÙŠØ±': f"{'+' if trend > 0 else ''}{trend:.1f}%",
                'Ø§Ù„Ø­Ø§Ù„Ø©': f"{status_color} {'Ù…ØºÙ„Ù‚' if compliance_percentage >= 50 else 'Ù…ÙØªÙˆØ­'}",
                'Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©': priority,
                'Ø§Ù„ØªÙˆØµÙŠØ©': recommendation,
                'trend_value': trend,
                'recent_compliance': recent_compliance
            }
            
            # Quarterly trend for detailed view
            if not recent_records_df.empty:
                # Group by quarter and calculate compliance percentage
                quarterly_trend_series = recent_records_df.groupby(recent_records_df['Ø§Ù„ØªØ§Ø±ÙŠØ®'].dt.quarter)['Ø§Ù„Ø­Ø§Ù„Ø©'].apply(
                    lambda x: (x.astype(str).str.contains('Ù…ØºÙ„Ù‚|Ù…ÙƒØªÙ…Ù„', case=False, na=False).sum() / len(x) * 100) if len(x) > 0 else 0
                )
                sector_data['quarterly_trends'] = quarterly_trend_series.to_dict()
            else:
                sector_data['quarterly_trends'] = {} # No quarterly data if no recent records

            compliance_data.append(sector_data)
            
        return pd.DataFrame(compliance_data)

    def get_risk_activities_summary(self, unified_data: dict, filters: dict = None) -> pd.DataFrame:
        """
        Generates a summary of risk activities.
        
        Args:
            unified_data (dict): Dictionary of unified DataFrames (e.g., {'risk_assessments': df}).
            filters (dict, optional): Dictionary of filters to apply. Defaults to None.
            
        Returns:
            pd.DataFrame: A DataFrame with risk metrics per activity.
        """
        risk_assessments_df = unified_data.get('risk_assessments', pd.DataFrame())
        
        if risk_assessments_df.empty:
            return pd.DataFrame()

        # Apply common filters
        filtered_risk_df = self._apply_common_filters(
            risk_assessments_df, filters,
            date_col_name='Ø§Ù„ØªØ§Ø±ÙŠØ®',
            sector_col_name='Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©',
            risk_level_col_name='Ø§Ù„ØªØµÙ†ÙŠÙ' # Pass risk_level_col_name to common filter
        )

        risk_data_list = []

        # Standardized column names from data_processor
        activity_col = 'Ø§Ù„Ù†Ø´Ø§Ø·' # Assuming 'ØªØµÙ†ÙŠÙ Ø§Ù„Ù†Ø´Ø§Ø·' is mapped to 'Ø§Ù„Ù†Ø´Ø§Ø·'
        risk_level_col = 'Ø§Ù„ØªØµÙ†ÙŠÙ' # Assuming 'Ø§Ù„ØªØµÙ†ÙŠÙ' or 'risk_level' is mapped to 'Ø§Ù„ØªØµÙ†ÙŠÙ'
        recommendation_col = 'Ø§Ù„ØªÙˆØµÙŠØ©_Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©' # Assuming 'Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„ØªØµØ­ÙŠØ­ÙŠØ© ÙˆØ§Ù„ØªÙˆØµÙŠØ§Øª' is mapped to 'Ø§Ù„ØªÙˆØµÙŠØ©_Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©'

        if activity_col not in filtered_risk_df.columns:
            print(f"Warning: '{activity_col}' column not found in risk assessments data.")
            return pd.DataFrame()
        
        # Handle missing 'Ø§Ù„ØªØµÙ†ÙŠÙ' column by deriving from 'Ù†Ø³Ø¨Ø©_Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©'
        if risk_level_col not in filtered_risk_df.columns:
            if 'Ù†Ø³Ø¨Ø©_Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©' in filtered_risk_df.columns:
                # Silently derive risk level from 'Ù†Ø³Ø¨Ø©_Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©'
                def categorize_risk_by_percentage(percentage):
                    try:
                        val = float(str(percentage).replace('%', ''))
                        if val >= 0.7: return 'Ø¹Ø§Ù„ÙŠ'
                        elif val >= 0.4: return 'Ù…ØªÙˆØ³Ø·'
                        else: return 'Ù…Ù†Ø®ÙØ¶'
                    except (ValueError, TypeError):
                        return 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'
                filtered_risk_df[risk_level_col] = filtered_risk_df['Ù†Ø³Ø¨Ø©_Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©'].apply(categorize_risk_by_percentage)
            else:
                # If neither column exists, create a default risk level
                filtered_risk_df[risk_level_col] = 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'
        
        # Use a predefined list of activities or derive from data if empty
        activities_to_analyze = filtered_risk_df[activity_col].dropna().unique().tolist()
        if not activities_to_analyze:
            activities_to_analyze = RISK_ACTIVITIES # Fallback to general list from config

        for activity in sorted(list(set(activities_to_analyze))):
            activity_df = filtered_risk_df[
                filtered_risk_df[activity_col].astype(str).str.contains(str(activity), case=False, na=False)
            ]
            
            if activity_df.empty:
                continue

            total_assessments = len(activity_df)
            
            # Count high risks using the standardized risk_level_col
            high_risk_count = activity_df[
                activity_df[risk_level_col].astype(str).str.contains('Ø¹Ø§Ù„ÙŠ|Ù…Ø±ØªÙØ¹', case=False, na=False)
            ].shape[0] # Use .shape[0] for row count of filtered df

            risk_percentage = (high_risk_count / total_assessments * 100) if total_assessments > 0 else 0

            # Determine risk level and priority
            risk_level_label = "ğŸŸ¢ Ù…Ù†Ø®ÙØ¶"
            priority_val = 3 # 1 (high), 2 (medium), 3 (low)
            recommendation = "Ù…Ø±Ø§Ù‚Ø¨Ø© Ø¯ÙˆØ±ÙŠØ©"

            if risk_percentage >= 70:
                risk_level_label = "ğŸ”´ Ø¹Ø§Ù„ÙŠ"
                priority_val = 1
                recommendation = "Ù…Ø±Ø§Ø¬Ø¹Ø© Ø¹Ø§Ø¬Ù„Ø©"
            elif risk_percentage >= 40:
                risk_level_label = "ğŸŸ¡ Ù…ØªÙˆØ³Ø·"
                priority_val = 2
                recommendation = "Ù…Ø±Ø§Ù‚Ø¨Ø© Ø¯ÙˆØ±ÙŠØ© Ù…ÙƒØ«ÙØ©"
            
            risk_data_list.append({
                'Ø§Ù„Ù†Ø´Ø§Ø·': activity,
                'Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…Ø§Øª': total_assessments,
                'Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ø¹Ø§Ù„ÙŠØ©': high_risk_count,
                'Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø±': risk_level_label,
                'Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø± %': float(risk_percentage),
                'Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©': priority_val, # Numeric priority for sorting
                'Ø§Ù„ØªÙˆØµÙŠØ©': recommendation,
                # Convert the DataFrame to a JSON string to avoid UnhashableTypeError
                'details_df': activity_df.astype(str).to_json(orient='records', date_format='iso')
            })

        df_risk_activities = pd.DataFrame(risk_data_list)
        
        # Apply recommendation filter from UI
        if filters and 'recommendation_filter' in filters and filters['recommendation_filter'] != "Ø§Ù„ÙƒÙ„":
            if filters['recommendation_filter'] == "Ø¹Ø§Ø¬Ù„":
                df_risk_activities = df_risk_activities[df_risk_activities['Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©'] == 1]
            elif filters['recommendation_filter'] == "Ù…ØªÙˆØ³Ø·":
                df_risk_activities = df_risk_activities[df_risk_activities['Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©'] == 2]
            elif filters['recommendation_filter'] == "Ù…Ù†Ø®ÙØ¶":
                df_risk_activities = df_risk_activities[df_risk_activities['Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©'] == 3]

        # Apply activity sort from UI
        if filters and 'activity_sort' in filters:
            if filters['activity_sort'] == "Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©":
                df_risk_activities = df_risk_activities.sort_values('Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©', ascending=True)
            elif filters['activity_sort'] == "Ø§Ù„Ø§Ø³Ù…":
                df_risk_activities = df_risk_activities.sort_values('Ø§Ù„Ù†Ø´Ø§Ø·', ascending=True)
            elif filters['activity_sort'] == "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø±":
                # Need to convert 'Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø± %' to numeric for proper sorting
                df_risk_activities['Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø± %_numeric'] = df_risk_activities['Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø± %'].astype(float) # Already float, just ensure
                df_risk_activities = df_risk_activities.sort_values('Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø± %_numeric', ascending=False)
                df_risk_activities = df_risk_activities.drop(columns=['Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø± %_numeric'])
                
        return df_risk_activities

    def get_incidents_summary(self, unified_data: dict, filters: dict = None) -> pd.DataFrame:
        """
        Generates a summary of incidents by sector, including closure rates.
        
        Args:
            unified_data (dict): Dictionary of unified DataFrames (e.g., {'incidents': df}).
            filters (dict, optional): Dictionary of filters to apply. Defaults to None.
            
        Returns:
            pd.DataFrame: A DataFrame with incident metrics per sector.
        """
        incidents_df = unified_data.get('incidents', pd.DataFrame())
        
        if incidents_df.empty:
            return pd.DataFrame()

        # Apply common filters
        filtered_incidents_df = self._apply_common_filters(
            incidents_df, filters,
            date_col_name='Ø§Ù„ØªØ§Ø±ÙŠØ®',
            sector_col_name='Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©',
            status_col_name='Ø§Ù„Ø­Ø§Ù„Ø©'
        )

        incidents_data_list = []

        # Determine actual sector column to use
        actual_sector_col = None
        if 'Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©' in filtered_incidents_df.columns:
            actual_sector_col = 'Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©'
        elif 'Ø§Ù„Ù‚Ø·Ø§Ø¹' in filtered_incidents_df.columns:
            actual_sector_col = 'Ø§Ù„Ù‚Ø·Ø§Ø¹'
        else:
            print("Warning: No suitable sector/department column found for incidents summary.")
            return pd.DataFrame()

        # Use unique sectors from the filtered data
        sectors_to_analyze = filtered_incidents_df[actual_sector_col].dropna().unique().tolist()
        if not sectors_to_analyze:
            sectors_to_analyze = SECTORS # Fallback

        for sector in sorted(list(set(sectors_to_analyze))):
            sector_incidents = filtered_incidents_df[
                filtered_incidents_df[actual_sector_col].astype(str).str.contains(str(sector), case=False, na=False)
            ]
            
            if sector_incidents.empty:
                continue

            total_incidents = len(sector_incidents)
            
            # Assuming 'Ø§Ù„ØªÙˆØµÙŠØ©_Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©' or similar is mapped to 'Ø§Ù„ØªÙˆØµÙŠØ©_Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©'
            # and 'Ø§Ù„Ø­Ø§Ù„Ø©' is mapped to 'Ø§Ù„Ø­Ø§Ù„Ø©'
            recommendations_count = sector_incidents['Ø§Ù„ØªÙˆØµÙŠØ©_Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©'].notna().sum() if 'Ø§Ù„ØªÙˆØµÙŠØ©_Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©' in sector_incidents.columns else total_incidents
            closed_count = sector_incidents['Ø§Ù„Ø­Ø§Ù„Ø©'].astype(str).str.contains('Ù…ØºÙ„Ù‚|Ù…ÙƒØªÙ…Ù„', case=False, na=False).sum()

            closure_percentage = (closed_count / recommendations_count * 100) if recommendations_count > 0 else 0

            incidents_data_list.append({
                'Ø§Ù„Ù‚Ø·Ø§Ø¹': sector,
                'Ø¹Ø¯Ø¯ Ø§Ù„Ø­ÙˆØ§Ø¯Ø«': total_incidents,
                'Ø¹Ø¯Ø¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª': recommendations_count,
                'Ù…ØºÙ„Ù‚': closed_count,
                'Ù…ÙØªÙˆØ­': recommendations_count - closed_count,
                'Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ %': float(closure_percentage)
            })

        return pd.DataFrame(incidents_data_list)
    
    def get_compliance_status_distribution(self, unified_data: dict, filters: dict = None) -> pd.DataFrame:
        """
        Extracts compliance status distribution from unified inspections data.
        """
        inspections_df = unified_data.get('inspections', pd.DataFrame())
        if inspections_df.empty:
            return pd.DataFrame()

        filtered_df = self._apply_common_filters(inspections_df, filters, status_col_name='Ø§Ù„Ø­Ø§Ù„Ø©')

        compliance_counts = {'Ù…ØºÙ„Ù‚': 0, 'Ù…ÙØªÙˆØ­': 0}
        if 'Ø§Ù„Ø­Ø§Ù„Ø©' in filtered_df.columns:
            status_counts = filtered_df['Ø§Ù„Ø­Ø§Ù„Ø©'].value_counts()
            compliance_counts['Ù…ØºÙ„Ù‚'] = status_counts.get('Ù…ØºÙ„Ù‚', 0)
            compliance_counts['Ù…ÙØªÙˆØ­'] = status_counts.get('Ù…ÙØªÙˆØ­', 0)
        
        return pd.DataFrame([
            {'status': 'Ù…ØºÙ„Ù‚', 'count': compliance_counts['Ù…ØºÙ„Ù‚']},
            {'status': 'Ù…ÙØªÙˆØ­', 'count': compliance_counts['Ù…ÙØªÙˆØ­']}
        ])

    def get_department_compliance_performance(self, unified_data: dict, filters: dict = None) -> pd.DataFrame:
        """
        Calculates department compliance performance metrics from unified inspections data.
        """
        inspections_df = unified_data.get('inspections', pd.DataFrame())
        if inspections_df.empty:
            return pd.DataFrame()
        
        filtered_df = self._apply_common_filters(inspections_df, filters, 
                                                sector_col_name='Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©', 
                                                status_col_name='Ø§Ù„Ø­Ø§Ù„Ø©')

        dept_performance = {}
        
        actual_dept_col = 'Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©' if 'Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©' in filtered_df.columns else \
                          'Ø§Ù„Ù‚Ø·Ø§Ø¹' if 'Ø§Ù„Ù‚Ø·Ø§Ø¹' in filtered_df.columns else None
        
        if actual_dept_col and 'Ø§Ù„Ø­Ø§Ù„Ø©' in filtered_df.columns:
            dept_status = filtered_df.groupby(actual_dept_col)['Ø§Ù„Ø­Ø§Ù„Ø©'].value_counts().unstack(fill_value=0)
            for dept in dept_status.index:
                closed = dept_status.loc[dept].get('Ù…ØºÙ„Ù‚', 0)
                total = dept_status.loc[dept].sum()
                compliance_rate = (closed / total * 100) if total > 0 else 0
                
                dept_performance[dept] = compliance_rate
        
        result = [{'department': dept, 'compliance_rate': rate} for dept, rate in dept_performance.items()]
        return pd.DataFrame(result)

    def get_risk_level_distribution(self, unified_data: dict, filters: dict = None) -> pd.DataFrame:
        """
        Extracts risk level distribution from unified risk assessments data.
        """
        risk_assessments_df = unified_data.get('risk_assessments', pd.DataFrame())
        if risk_assessments_df.empty:
            return pd.DataFrame()
        
        filtered_df = self._apply_common_filters(risk_assessments_df, filters, risk_level_col_name='Ø§Ù„ØªØµÙ†ÙŠÙ')

        risk_level_col = 'Ø§Ù„ØªØµÙ†ÙŠÙ' # Standardized column name
        if risk_level_col not in filtered_df.columns:
            # Fallback to deriving from 'Ù†Ø³Ø¨Ø©_Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©' if 'Ø§Ù„ØªØµÙ†ÙŠÙ' is missing
            if 'Ù†Ø³Ø¨Ø©_Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©' in filtered_df.columns:
                def categorize_risk_by_percentage(percentage):
                    try:
                        val = float(str(percentage).replace('%', ''))
                        if val >= 0.7: return 'Ø¹Ø§Ù„ÙŠ'
                        elif val >= 0.4: return 'Ù…ØªÙˆØ³Ø·'
                        else: return 'Ù…Ù†Ø®ÙØ¶'
                    except (ValueError, TypeError):
                        return 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'
                filtered_df[risk_level_col] = filtered_df['Ù†Ø³Ø¨Ø©_Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©'].apply(categorize_risk_by_percentage)
            else:
                return pd.DataFrame() # Cannot determine risk levels

        risk_counts = filtered_df[risk_level_col].value_counts().to_dict()
        
        # Ensure all standard risk levels are present, even if count is 0
        standard_risk_levels = ['Ø¹Ø§Ù„ÙŠ', 'Ù…ØªÙˆØ³Ø·', 'Ù…Ù†Ø®ÙØ¶']
        for level in standard_risk_levels:
            if level not in risk_counts:
                risk_counts[level] = 0

        return pd.DataFrame([
            {'risk_level': level, 'count': count}
            for level, count in risk_counts.items()
        ]).sort_values('risk_level', ascending=False) # Sort for consistent display

    def get_risk_trend_over_time(self, unified_data: dict, filters: dict = None) -> pd.DataFrame:
        """
        Calculates risk trend over time from unified risk assessments data.
        """
        risk_assessments_df = unified_data.get('risk_assessments', pd.DataFrame())
        if risk_assessments_df.empty:
            return pd.DataFrame()
        
        filtered_df = self._apply_common_filters(risk_assessments_df, filters, date_col_name='Ø§Ù„ØªØ§Ø±ÙŠØ®')

        date_col = 'Ø§Ù„ØªØ§Ø±ÙŠØ®'
        risk_score_col = 'Ù†Ø³Ø¨Ø©_Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©' # Standardized column for numeric risk score

        if date_col not in filtered_df.columns or risk_score_col not in filtered_df.columns:
            return pd.DataFrame()
        
        # Ensure risk_score_col is numeric
        filtered_df[risk_score_col] = pd.to_numeric(filtered_df[risk_score_col], errors='coerce')
        
        trend_data = filtered_df[[date_col, risk_score_col]].dropna()
        
        if trend_data.empty:
            return pd.DataFrame()

        # Group by month for trend
        trend_data = trend_data.groupby(pd.Grouper(key=date_col, freq='M')).agg(
            risk_score=(risk_score_col, 'mean')
        ).reset_index()
        
        trend_data.columns = ['date', 'risk_score']
        
        # Categorize risk level for coloring/labeling
        trend_data['risk_level'] = pd.cut(
            trend_data['risk_score'],
            bins=[0, 0.3, 0.7, 1.0], # Example bins, adjust as per your risk model
            labels=['Ù…Ù†Ø®ÙØ¶', 'Ù…ØªÙˆØ³Ø·', 'Ø¹Ø§Ù„ÙŠ'],
            right=True # Include the rightmost bin edge
        )
        
        return trend_data

    def prepare_activity_heatmap_data(self, unified_data: dict, filters: dict = None) -> pd.DataFrame:
        """
        Prepares data for an activity heatmap, showing density by department and activity type.
        """
        all_data_for_heatmap = pd.DataFrame()
        # Concatenate relevant dataframes for heatmap (e.g., inspections, incidents, risk_assessments)
        for key in ['inspections', 'incidents', 'risk_assessments', 'contractor_audits', 'safety_checks', 'recommendations']:
            df = unified_data.get(key)
            if df is not None and not df.empty:
                # Select relevant columns, assuming 'Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©'/'Ø§Ù„Ù‚Ø·Ø§Ø¹' and 'Ø§Ù„Ù†Ø´Ø§Ø·' are standardized
                if 'Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©' in df.columns and 'Ø§Ù„Ù†Ø´Ø§Ø·' in df.columns:
                    all_data_for_heatmap = pd.concat([all_data_for_heatmap, df[['Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©', 'Ø§Ù„Ù†Ø´Ø§Ø·']]], ignore_index=True)
                elif 'Ø§Ù„Ù‚Ø·Ø§Ø¹' in df.columns and 'Ø§Ù„Ù†Ø´Ø§Ø·' in df.columns:
                     all_data_for_heatmap = pd.concat([all_data_for_heatmap, df[['Ø§Ù„Ù‚Ø·Ø§Ø¹', 'Ø§Ù„Ù†Ø´Ø§Ø·']].rename(columns={'Ø§Ù„Ù‚Ø·Ø§Ø¹': 'Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©'})], ignore_index=True)

        if all_data_for_heatmap.empty:
            return pd.DataFrame()
        
        # Apply common filters to the combined data
        filtered_data_for_heatmap = self._apply_common_filters(
            all_data_for_heatmap, filters,
            sector_col_name='Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©',
            activity_col_name='Ø§Ù„Ù†Ø´Ø§Ø·'
        )

        if filtered_data_for_heatmap.empty or 'Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©' not in filtered_data_for_heatmap.columns or 'Ø§Ù„Ù†Ø´Ø§Ø·' not in filtered_data_for_heatmap.columns:
            return pd.DataFrame()

        # Clean and standardize department and activity names
        filtered_data_for_heatmap['Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©'] = filtered_data_for_heatmap['Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©'].astype(str).str.strip()
        filtered_data_for_heatmap['Ø§Ù„Ù†Ø´Ø§Ø·'] = filtered_data_for_heatmap['Ø§Ù„Ù†Ø´Ø§Ø·'].astype(str).str.strip()

        # Create a pivot table (cross-tabulation)
        heatmap_pivot = pd.crosstab(
            filtered_data_for_heatmap['Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©'], 
            filtered_data_for_heatmap['Ø§Ù„Ù†Ø´Ø§Ø·'], 
            dropna=False # Keep NaN values if any, though _clean_text_data should handle it
        )
        
        # Fill any NaN values (where a combination doesn't exist) with 0
        heatmap_matrix = heatmap_pivot.fillna(0)
        
        return heatmap_matrix

    def get_time_series_data(self, unified_data: dict, data_type_key: str, filters: dict = None) -> pd.DataFrame:
        """
        Extracts and aggregates time series data for a specific unified data type.
        """
        df = unified_data.get(data_type_key, pd.DataFrame())
        if df.empty:
            return pd.DataFrame()
        
        filtered_df = self._apply_common_filters(df, filters, date_col_name='Ø§Ù„ØªØ§Ø±ÙŠØ®')

        date_col = 'Ø§Ù„ØªØ§Ø±ÙŠØ®'
        if date_col not in filtered_df.columns or not pd.api.types.is_datetime64_any_dtype(filtered_df[date_col]):
            return pd.DataFrame()
        
        # Group by month for trend
        time_series = filtered_df.groupby(pd.Grouper(key=date_col, freq='M')).size().reset_index()
        time_series.columns = ['date', 'count']
        
        return time_series

    def generate_analytics_insights(self, unified_data: dict, filters: dict = None) -> list:
        """
        Generates AI-powered analytics insights based on the unified data.
        This function now uses the analyzer's own methods to get aggregated data.
        """
        insights = []

        # Insight 1: Data completeness (using overall KPI data)
        overall_kpis = {}
        # Access kpi_data from st.session_state as it's generated by DataProcessor and stored there
        if 'kpi_data' in st.session_state:
            for kpi_type, kpi_info in st.session_state.kpi_data.items():
                if kpi_info and kpi_info.get('total_records') is not None:
                    overall_kpis[kpi_type] = kpi_info

        total_records_overall = sum([data.get('total_records', 0) for data in overall_kpis.values()])
        if total_records_overall > 0:
            insights.append({
                'title': 'Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª',
                'description': f'ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¹Ù„Ù‰ {total_records_overall:,} Ø³Ø¬Ù„ Ø¹Ø¨Ø± {len(overall_kpis)} Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª.',
                'recommendation': 'ØªØ£ÙƒØ¯ Ù…Ù† ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ù†ØªØ¸Ø§Ù… Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø¤Ù‰ Ø¯Ù‚ÙŠÙ‚Ø©.',
                'priority': 'Ù…ØªÙˆØ³Ø·'
            })
        
        # Insight 2: Compliance Rate
        compliance_summary_df = self.get_compliance_summary(unified_data, filters)
        if not compliance_summary_df.empty:
            overall_compliance_rate = compliance_summary_df['Ù†Ø³Ø¨Ø© Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ %'].mean()
            
            if overall_compliance_rate < 70:
                priority = 'Ø¹Ø§Ù„ÙŠ'
                recommendation = 'Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ù…Ù†Ø®ÙØ¶. ÙŠØ¬Ø¨ Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©.'
            elif overall_compliance_rate < 85:
                priority = 'Ù…ØªÙˆØ³Ø·'
                recommendation = 'Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ø¬ÙŠØ¯ ÙˆÙ„ÙƒÙ† ÙŠÙ…ÙƒÙ† ØªØ­Ø³ÙŠÙ†Ù‡.'
            else:
                priority = 'Ù…Ù†Ø®ÙØ¶'
                recommendation = 'Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…tØ«tØ§Ù„ Ù…Ù…ØªØ§Ø². Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø£Ø¯Ø§Ø¡.'
            
            insights.append({
                'title': 'Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ',
                'description': f'Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø­Ø§Ù„ÙŠ Ù‡Ùˆ {overall_compliance_rate:.1f}%.',
                'recommendation': recommendation,
                'priority': priority
            })
        
        # Insight 3: Top Risk Activity
        risk_activities_summary_df = self.get_risk_activities_summary(unified_data, filters)
        if not risk_activities_summary_df.empty:
            # Sort by priority (1=high, 3=low) to find the most critical activity
            most_critical_activity_row = risk_activities_summary_df.sort_values('Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©', ascending=True).iloc[0]
            
            insights.append({
                'title': 'Ø§Ù„Ù†Ø´Ø§Ø· Ø§Ù„Ø£ÙƒØ«Ø± Ø®Ø·ÙˆØ±Ø©',
                'description': f'Ø§Ù„Ù†Ø´Ø§Ø· Ø§Ù„Ø£ÙƒØ«Ø± Ø®Ø·ÙˆØ±Ø© Ù‡Ùˆ "{most_critical_activity_row["Ø§Ù„Ù†Ø´Ø§Ø·"]}" Ø¨Ù…Ø³ØªÙˆÙ‰ Ù…Ø®Ø§Ø·Ø± "{most_critical_activity_row["Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø±"]}" ÙˆÙ†Ø³Ø¨Ø© Ù…Ø®Ø§Ø·Ø± {most_critical_activity_row["Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø± %"]}.',
                'recommendation': most_critical_activity_row['Ø§Ù„ØªÙˆØµÙŠØ©'],
                'priority': most_critical_activity_row['Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©'] # Use the string priority
            })

        # Insight 4: Incident Closure Rate
        incidents_summary_df = self.get_incidents_summary(unified_data, filters)
        if not incidents_summary_df.empty:
            total_closed_incidents = incidents_summary_df['Ù…ØºÙ„Ù‚'].sum()
            total_recommendations_incidents = incidents_summary_df['Ø¹Ø¯Ø¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª'].sum()
            overall_incident_closure_rate = (total_closed_incidents / total_recommendations_incidents * 100) if total_recommendations_incidents > 0 else 0

            if overall_incident_closure_rate < 70:
                priority = 'Ø¹Ø§Ù„ÙŠ'
                recommendation = 'Ù…Ø¹Ø¯Ù„ Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ù…Ù†Ø®ÙØ¶. ÙŠØ¬Ø¨ ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„ØªØµØ­ÙŠØ­ÙŠØ© Ù„Ù„Ø­ÙˆØ§Ø¯Ø« Ø§Ù„Ù…ÙØªÙˆØ­Ø©.'
            elif overall_incident_closure_rate < 90:
                priority = 'Ù…ØªÙˆØ³Ø·'
                recommendation = 'Ù…Ø¹Ø¯Ù„ Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ø¬ÙŠØ¯. Ø§Ø³ØªÙ…Ø± ÙÙŠ Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø© Ù„ØªØ­Ù‚ÙŠÙ‚ Ù†Ø³Ø¨Ø© Ø£Ø¹Ù„Ù‰.'
            else:
                priority = 'Ù…Ù†Ø®ÙØ¶'
                recommendation = 'Ù…Ø¹Ø¯Ù„ Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ù…Ù…ØªØ§Ø². Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ ÙØ¹Ø§Ù„ÙŠØ© Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø¥ØºÙ„Ø§Ù‚.'
            
            insights.append({
                'title': 'Ù…Ø¹Ø¯Ù„ Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø­ÙˆØ§Ø¯Ø«',
                'description': f'Ù…Ø¹Ø¯Ù„ Ø¥ØºÙ„Ø§Ù‚ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù‡Ùˆ {overall_incident_closure_rate:.1f}%.',
                'recommendation': recommendation,
                'priority': priority
            })
        
        return insights


# Example usage (for testing this module independently)
def main():
    # This example requires data_processor to be functional
    from src.utils.data_processor import SafetyDataProcessor
    
    processor = SafetyDataProcessor()
    
    # Load all raw data
    raw_data_sources = processor.load_all_data()
            
    # Create unified dataset
    unified_data = processor.create_unified_dataset(raw_data_sources)
    
    analyzer = DashboardAnalyzer()

    # Test compliance summary
    compliance_df = analyzer.get_compliance_summary(unified_data)
    print("\n--- Compliance Summary ---")
    print(compliance_df.head())
    
    # Test risk activities summary
    risk_df = analyzer.get_risk_activities_summary(unified_data)
    print("\n--- Risk Activities Summary ---")
    print(risk_df.head())

    # Test incidents summary
    incidents_df = analyzer.get_incidents_summary(unified_data)
    print("\n--- Incidents Summary ---")
    print(incidents_df.head())

    # Test new analytical functions
    compliance_dist = analyzer.get_compliance_status_distribution(unified_data)
    print("\n--- Compliance Status Distribution ---")
    print(compliance_dist)

    dept_perf = analyzer.get_department_compliance_performance(unified_data)
    print("\n--- Department Compliance Performance ---")
    print(dept_perf.head())

    risk_dist = analyzer.get_risk_level_distribution(unified_data)
    print("\n--- Risk Level Distribution ---")
    print(risk_dist)

    risk_trend = analyzer.get_risk_trend_over_time(unified_data)
    print("\n--- Risk Trend Over Time ---")
    print(risk_trend.head())

    heatmap_data = analyzer.prepare_activity_heatmap_data(unified_data)
    print("\n--- Activity Heatmap Data ---")
    print(heatmap_data.head())

    time_series_obs = analyzer.get_time_series_data(unified_data, 'inspections')
    print("\n--- Observations Time Series ---")
    print(time_series_obs.head())
    
    insights = analyzer.generate_analytics_insights(unified_data)
    print("\n--- Generated Insights ---")
    for insight in insights:
        print(f"Title: {insight['title']}, Priority: {insight['priority']}")


if __name__ == "__main__":
    main()
